#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«‹å³å¯ç”¨çš„é å”®å±‹é¢¨éšªåˆ†æç³»çµ±
===========================

ä¿®æ­£äº†åƒæ•¸éŒ¯èª¤ï¼Œç¢ºä¿å¯ä»¥ç«‹å³é‹è¡Œ
åŒ…å«ç›¸å°é¢¨éšªåˆ†ç´šåŠŸèƒ½
"""
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import re

warnings.filterwarnings('ignore')

class WorkingPreSaleRiskAnalyzer:
    """å¯æ­£å¸¸é‹è¡Œçš„é å”®å±‹é¢¨éšªåˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.sale_data = None
        self.transaction_data = None
        
    def load_data(self, sale_file: str, transaction_file: str) -> bool:
        """è¼‰å…¥é å”®å±‹æ•¸æ“š"""
        try:
            self.sale_data = pd.read_csv(sale_file, encoding='utf-8')
            print(f"âœ… æˆåŠŸè¼‰å…¥éŠ·å”®è³‡æ–™: {len(self.sale_data)} ç­†")
            
            self.transaction_data = pd.read_csv(transaction_file, encoding='utf-8')
            print(f"âœ… æˆåŠŸè¼‰å…¥æˆäº¤è³‡æ–™: {len(self.transaction_data)} ç­†")
            
            self._preprocess_data()
            return True
            
        except Exception as e:
            print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {str(e)}")
            return False
    
    def _preprocess_data(self):
        """è³‡æ–™é è™•ç†"""
        print("ğŸ”„ é–‹å§‹è³‡æ–™é è™•ç†...")
        
        # è™•ç†éŠ·å”®è³‡æ–™
        if self.sale_data is not None:
            self.sale_data['éŠ·å”®èµ·å§‹å¹´å­£_clean'] = self.sale_data['éŠ·å”®èµ·å§‹å¹´å­£'].fillna('æœªçŸ¥')
            self.sale_data['åœ°å€'] = self.sale_data['ç¸£å¸‚'] + '-' + self.sale_data['è¡Œæ”¿å€']
            self.sale_data['æˆ¶æ•¸'] = pd.to_numeric(self.sale_data['æˆ¶æ•¸'], errors='coerce').fillna(0)
            self._process_sales_time_data()
        
        # è™•ç†æˆäº¤è³‡æ–™
        if self.transaction_data is not None:
            self.transaction_data['äº¤æ˜“å¹´æœˆ'] = pd.to_numeric(self.transaction_data['äº¤æ˜“å¹´æœˆ'], errors='coerce')
            self.transaction_data['åœ°å€'] = self.transaction_data['ç¸£å¸‚'] + '-' + self.transaction_data['è¡Œæ”¿å€']
            self.transaction_data['äº¤æ˜“ç¸½åƒ¹'] = pd.to_numeric(self.transaction_data['äº¤æ˜“ç¸½åƒ¹'], errors='coerce')
            self.transaction_data['å»ºç‰©å–®åƒ¹'] = pd.to_numeric(self.transaction_data['å»ºç‰©å–®åƒ¹'], errors='coerce')
            self._process_transaction_time_data()
        
        print("âœ… è³‡æ–™é è™•ç†å®Œæˆ")
    
    def _process_sales_time_data(self):
        """è™•ç†éŠ·å”®æ™‚é–“ç›¸é—œæ•¸æ“š"""
        print("â° è™•ç†éŠ·å”®æ™‚é–“æ•¸æ“š...")
        
        self.sale_data['éŠ·å”®èµ·å§‹æ—¥æœŸ'] = self.sale_data['éŠ·å”®èµ·å§‹æ™‚é–“'].apply(self._convert_roc_date)
        self.sale_data['éŠ·å”®çµæŸæ—¥æœŸ'] = self.sale_data['éŠ·å”®æœŸé–“'].apply(self._parse_sales_period)
        
        current_date = datetime.now()
        self.sale_data['éŠ·å”®å¤©æ•¸'] = self.sale_data.apply(
            lambda row: self._calculate_sales_days(row['éŠ·å”®èµ·å§‹æ—¥æœŸ'], row['éŠ·å”®çµæŸæ—¥æœŸ'], current_date), 
            axis=1
        )
        
        self.sale_data['éŠ·å”®æœˆæ•¸'] = self.sale_data['éŠ·å”®å¤©æ•¸'] / 30.44
        self.sale_data['éŠ·å”®éšæ®µ'] = self.sale_data['éŠ·å”®æœˆæ•¸'].apply(self._classify_sales_stage)
        
        print(f"âœ… éŠ·å”®æ™‚é–“è™•ç†å®Œæˆï¼Œæœ‰æ•ˆæ—¥æœŸæ•¸: {self.sale_data['éŠ·å”®èµ·å§‹æ—¥æœŸ'].notna().sum()}")
    
    def _process_transaction_time_data(self):
        """è™•ç†æˆäº¤æ™‚é–“ç›¸é—œæ•¸æ“š"""
        print("â° è™•ç†æˆäº¤æ™‚é–“æ•¸æ“š...")
        
        self.transaction_data['äº¤æ˜“æ—¥æœŸ_parsed'] = self.transaction_data['äº¤æ˜“å¹´æœˆ'].apply(
            lambda x: self._convert_year_month_to_date(x) if pd.notna(x) else None
        )
        
        print(f"âœ… æˆäº¤æ™‚é–“è™•ç†å®Œæˆï¼Œæœ‰æ•ˆæ—¥æœŸæ•¸: {self.transaction_data['äº¤æ˜“æ—¥æœŸ_parsed'].notna().sum()}")
    
    def _convert_roc_date(self, roc_date):
        """è½‰æ›æ°‘åœ‹å¹´æ—¥æœŸç‚ºæ¨™æº–æ—¥æœŸæ ¼å¼"""
        if pd.isna(roc_date) or roc_date == 'null':
            return None
        
        try:
            date_str = str(int(roc_date))
            
            if len(date_str) == 7:
                year = int(date_str[:3]) + 1911
                month = int(date_str[3:5])
                day = int(date_str[5:7])
                return datetime(year, month, day)
            elif len(date_str) == 6:
                year = int(date_str[:3]) + 1911
                month = int(date_str[3:5])
                day = int(date_str[5:6]) if len(date_str[5:]) == 1 else int(date_str[5:])
                return datetime(year, month, day)
            else:
                return None
                
        except (ValueError, TypeError):
            return None
    
    def _convert_year_month_to_date(self, year_month):
        """è½‰æ›YYYAAæ ¼å¼çš„å¹´æœˆç‚ºæ—¥æœŸ"""
        if pd.isna(year_month):
            return None
        
        try:
            year_month_str = str(int(year_month))
            if len(year_month_str) >= 5:
                year = int(year_month_str[:3]) + 1911
                month = int(year_month_str[3:5])
                return datetime(year, month, 1)
            return None
        except (ValueError, TypeError):
            return None
    
    def _parse_sales_period(self, period_str):
        """è§£æéŠ·å”®æœŸé–“å­—ä¸²"""
        if pd.isna(period_str) or period_str in ['ç„¡', 'null', '']:
            return None
        
        try:
            if '~' in str(period_str):
                parts = str(period_str).split('~')
                if len(parts) >= 2:
                    end_part = parts[1].strip()
                    
                    if re.match(r'\d{7}', end_part):
                        return self._convert_roc_date(end_part)
                    elif 'å®Œå”®' in end_part or 'å”®å®Œ' in end_part:
                        return None
            
            if 'å®ŒéŠ·' in str(period_str) or 'å”®å®Œ' in str(period_str):
                return None
                
        except Exception:
            pass
        
        return None
    
    def _calculate_sales_days(self, start_date, end_date, current_date):
        """è¨ˆç®—éŠ·å”®å¤©æ•¸"""
        if pd.isna(start_date):
            return 0
        
        if pd.isna(end_date):
            end_date = current_date
        
        return (end_date - start_date).days
    
    def _classify_sales_stage(self, sales_months):
        """åˆ†é¡éŠ·å”®éšæ®µ"""
        if pd.isna(sales_months) or sales_months <= 0:
            return 'æœªçŸ¥'
        
        if sales_months < 6:
            return 'æ–°é–‹æ¡ˆ'
        elif sales_months < 24:
            return 'ç©æ¥µéŠ·å”®'
        elif sales_months < 48:
            return 'å°¾ç›¤éŠ·å”®'
        else:
            return 'é•·æœŸéŠ·å”®'
    
    def calculate_time_adjusted_absorption_rate(self, by_quarter: bool = True, min_sales_months: float = 1.0) -> pd.DataFrame:
        """è¨ˆç®—æ™‚é–“èª¿æ•´çš„é å”®å±‹å»åŒ–ç‡"""
        if self.sale_data is None or self.transaction_data is None:
            raise ValueError("è«‹å…ˆè¼‰å…¥æ•¸æ“š")
        
        print("ğŸ“Š è¨ˆç®—æ™‚é–“èª¿æ•´é å”®å±‹å»åŒ–ç‡...")
        
        # ç¯©é¸æœ‰æ•ˆçš„éŠ·å”®æ•¸æ“š
        valid_sales = self.sale_data[
            (self.sale_data['éŠ·å”®æœˆæ•¸'] >= min_sales_months) & 
            (self.sale_data['æˆ¶æ•¸'] > 0)
        ].copy()
        
        print(f"æœ‰æ•ˆéŠ·å”®é …ç›®æ•¸: {len(valid_sales)} (åŸå§‹: {len(self.sale_data)})")
        
        results = []
        
        # æŒ‰åœ°å€å’Œæ™‚é–“åˆ†çµ„è¨ˆç®—
        group_cols = ['åœ°å€']
        if by_quarter:
            group_cols.append('äº¤æ˜“å¹´å­£')
        
        # è¨ˆç®—å„åœ°å€çš„ä¾›çµ¦æ•¸æ“š
        region_supply = valid_sales.groupby('åœ°å€').agg({
            'æˆ¶æ•¸': 'sum',
            'éŠ·å”®æœˆæ•¸': 'mean',
            'ç·¨è™Ÿ': 'count'
        }).reset_index()
        region_supply.columns = ['åœ°å€', 'ç¸½æˆ¶æ•¸', 'å¹³å‡éŠ·å”®æœˆæ•¸', 'é …ç›®æ•¸']
        
        # è¨ˆç®—å„åœ°å€å„å­£çš„æˆäº¤ç­†æ•¸
        demand_stats = self.transaction_data.groupby(group_cols).agg({
            'å‚™æŸ¥ç·¨è™Ÿ': 'count',
            'äº¤æ˜“ç¸½åƒ¹': ['sum', 'mean'],
            'å»ºç‰©å–®åƒ¹': 'mean'
        }).reset_index()
        
        if by_quarter:
            demand_stats.columns = ['åœ°å€', 'äº¤æ˜“å¹´å­£', 'æˆäº¤ç­†æ•¸', 'ç¸½äº¤æ˜“é‡‘é¡', 'å¹³å‡äº¤æ˜“åƒ¹', 'å¹³å‡å»ºç‰©å–®åƒ¹']
        else:
            demand_stats.columns = ['åœ°å€', 'æˆäº¤ç­†æ•¸', 'ç¸½äº¤æ˜“é‡‘é¡', 'å¹³å‡äº¤æ˜“åƒ¹', 'å¹³å‡å»ºç‰©å–®åƒ¹']
        
        # åˆä½µä¾›éœ€æ•¸æ“š
        if by_quarter:
            for quarter in demand_stats['äº¤æ˜“å¹´å­£'].unique():
                quarter_data = demand_stats[demand_stats['äº¤æ˜“å¹´å­£'] == quarter]
                merged = quarter_data.merge(region_supply, on='åœ°å€', how='left')
                
                # è¨ˆç®—æ™‚é–“èª¿æ•´å»åŒ–ç‡
                merged['æ¨™æº–å»åŒ–ç‡'] = merged['æˆäº¤ç­†æ•¸'] / merged['ç¸½æˆ¶æ•¸']
                merged['æ¨™æº–å»åŒ–ç‡'] = merged['æ¨™æº–å»åŒ–ç‡'].fillna(0).clip(0, 1)
                
                # è¨ˆç®—æœˆå»åŒ–ç‡
                merged['æœˆå»åŒ–ç‡'] = merged['æ¨™æº–å»åŒ–ç‡'] / merged['å¹³å‡éŠ·å”®æœˆæ•¸']
                merged['æœˆå»åŒ–ç‡'] = merged['æœˆå»åŒ–ç‡'].fillna(0)
                
                # è¨ˆç®—æ™‚é–“èª¿æ•´å»åŒ–ç‡
                merged['æ™‚é–“èª¿æ•´å»åŒ–ç‡'] = merged.apply(
                    lambda row: self._calculate_time_weighted_absorption(
                        row['æ¨™æº–å»åŒ–ç‡'], row['å¹³å‡éŠ·å”®æœˆæ•¸']
                    ), axis=1
                )
                
                # è¨ˆç®—éŠ·å”®æ•ˆç‡åˆ†æ•¸
                merged['éŠ·å”®æ•ˆç‡åˆ†æ•¸'] = merged.apply(
                    lambda row: self._calculate_sales_efficiency_score(
                        row['æˆäº¤ç­†æ•¸'], row['å¹³å‡éŠ·å”®æœˆæ•¸'], row['é …ç›®æ•¸']
                    ), axis=1
                )
                
                merged['åˆ†ææ™‚é–“'] = quarter
                results.append(merged)
        else:
            merged = demand_stats.merge(region_supply, on='åœ°å€', how='left')
            
            # è¨ˆç®—å„é …æŒ‡æ¨™
            merged['æ¨™æº–å»åŒ–ç‡'] = merged['æˆäº¤ç­†æ•¸'] / merged['ç¸½æˆ¶æ•¸']
            merged['æ¨™æº–å»åŒ–ç‡'] = merged['æ¨™æº–å»åŒ–ç‡'].fillna(0).clip(0, 1)
            
            merged['æœˆå»åŒ–ç‡'] = merged['æ¨™æº–å»åŒ–ç‡'] / merged['å¹³å‡éŠ·å”®æœˆæ•¸']
            merged['æœˆå»åŒ–ç‡'] = merged['æœˆå»åŒ–ç‡'].fillna(0)
            
            merged['æ™‚é–“èª¿æ•´å»åŒ–ç‡'] = merged.apply(
                lambda row: self._calculate_time_weighted_absorption(
                    row['æ¨™æº–å»åŒ–ç‡'], row['å¹³å‡éŠ·å”®æœˆæ•¸']
                ), axis=1
            )
            
            merged['éŠ·å”®æ•ˆç‡åˆ†æ•¸'] = merged.apply(
                lambda row: self._calculate_sales_efficiency_score(
                    row['æˆäº¤ç­†æ•¸'], row['å¹³å‡éŠ·å”®æœˆæ•¸'], row['é …ç›®æ•¸']
                ), axis=1
            )
            
            results.append(merged)
        
        result_df = pd.concat(results, ignore_index=True) if results else pd.DataFrame()
        
        print(f"âœ… å®Œæˆ {len(result_df)} ç­†æ™‚é–“èª¿æ•´å»åŒ–ç‡è¨ˆç®—")
        return result_df
    
    def _calculate_time_weighted_absorption(self, standard_rate: float, sales_months: float) -> float:
        """è¨ˆç®—æ™‚é–“åŠ æ¬Šå»åŒ–ç‡"""
        if pd.isna(standard_rate) or pd.isna(sales_months) or sales_months <= 0:
            return 0
        
        baseline_months = 12
        
        if sales_months < baseline_months:
            time_factor = min(baseline_months / sales_months, 2.0)
        else:
            time_factor = max(baseline_months / sales_months, 0.5)
        
        adjusted_rate = standard_rate * time_factor
        return min(adjusted_rate, 1.0)
    
    def _calculate_sales_efficiency_score(self, transactions: int, sales_months: float, projects: int) -> float:
        """è¨ˆç®—éŠ·å”®æ•ˆç‡åˆ†æ•¸"""
        if pd.isna(sales_months) or sales_months <= 0 or projects <= 0:
            return 0
        
        monthly_transactions = transactions / sales_months
        efficiency_per_project = monthly_transactions / projects
        
        return efficiency_per_project
    
    def classify_risk_with_relative_option(self, indicators: pd.DataFrame, use_relative: bool = True) -> pd.DataFrame:
        """é¢¨éšªåˆ†ç´šï¼ˆå«ç›¸å°åˆ†ç´šé¸é …ï¼‰"""
        print("ğŸ¯ é€²è¡Œæ™‚é–“èª¿æ•´é¢¨éšªç­‰ç´šåˆ†é¡...")
        
        result = indicators.copy()
        
        # é¦–å…ˆé€²è¡Œçµ•å°åˆ†ç´š
        result = self._absolute_risk_classification(result)
        
        # å¦‚æœä½¿ç”¨ç›¸å°åˆ†ç´š
        if use_relative:
            result = self._relative_risk_classification(result)
        
        print("âœ… é¢¨éšªåˆ†ç´šå®Œæˆ")
        return result
    
    def _absolute_risk_classification(self, data: pd.DataFrame) -> pd.DataFrame:
        """çµ•å°æ¨™æº–é¢¨éšªåˆ†ç´š"""
        result = data.copy()
        
        # åˆå§‹åŒ–é¢¨éšªç­‰ç´š
        result['çµ•å°é¢¨éšªç­‰ç´š'] = 'ğŸŸ¢ ä½é¢¨éšª'
        result['é¢¨éšªåˆ†æ•¸'] = 0
        result['ä¸»è¦é¢¨éšªå› å­'] = ''
        
        for idx, row in result.iterrows():
            risk_factors = []
            risk_score = 0
            
            # æ™‚é–“èª¿æ•´å»åŒ–ç‡é¢¨éšª
            time_adj_rate = row.get('æ™‚é–“èª¿æ•´å»åŒ–ç‡', 0)
            if time_adj_rate < 0.25:
                risk_factors.append('æ™‚é–“èª¿æ•´å»åŒ–ç‡åä½')
                risk_score += 3
            elif time_adj_rate > 0.65:
                risk_factors.append('å¯èƒ½éåº¦éŠ·å”®')
                risk_score += 1
            
            # æœˆå»åŒ–ç‡é¢¨éšª
            monthly_rate = row.get('æœˆå»åŒ–ç‡', 0)
            if monthly_rate < 0.05:
                risk_factors.append('éŠ·å”®æ•ˆç‡ä½è½')
                risk_score += 2
            
            # æˆäº¤é‡é¢¨éšª
            transactions = row.get('æˆäº¤ç­†æ•¸', 0)
            if transactions == 0:
                risk_factors.append('å®Œå…¨ç„¡æˆäº¤')
                risk_score += 4
            elif transactions < 5:
                risk_factors.append('æˆäº¤é‡æ¥µä½')
                risk_score += 2
            
            # éŠ·å”®æœŸé–“é¢¨éšª
            avg_sales_months = row.get('å¹³å‡éŠ·å”®æœˆæ•¸', 0)
            if avg_sales_months > 36:
                risk_factors.append('éŠ·å”®æœŸé–“éé•·')
                risk_score += 1
            
            # ç¶œåˆé¢¨éšªç­‰ç´šåˆ¤å®š
            if risk_score >= 5:
                result.loc[idx, 'çµ•å°é¢¨éšªç­‰ç´š'] = 'ğŸ”´ é«˜é¢¨éšª'
            elif risk_score >= 2.5:
                result.loc[idx, 'çµ•å°é¢¨éšªç­‰ç´š'] = 'ğŸŸ¡ ä¸­é¢¨éšª'
            
            result.loc[idx, 'é¢¨éšªåˆ†æ•¸'] = risk_score
            result.loc[idx, 'ä¸»è¦é¢¨éšªå› å­'] = '; '.join(risk_factors) if risk_factors else 'ç„¡æ˜é¡¯é¢¨éšª'
        
        # è¨­å®šé è¨­é¢¨éšªç­‰ç´š
        result['é¢¨éšªç­‰ç´š'] = result['çµ•å°é¢¨éšªç­‰ç´š']
        
        return result
    
    def _relative_risk_classification(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç›¸å°æ¨™æº–é¢¨éšªåˆ†ç´šï¼ˆåŒç¸£å¸‚å…§æ¯”è¼ƒï¼‰"""
        print("   ğŸ“Š åŸ·è¡ŒåŒç¸£å¸‚å…§ç›¸å°é¢¨éšªåˆ†ç´š...")
        
        result = data.copy()
        
        # æå–ç¸£å¸‚è³‡è¨Š
        result['ç¸£å¸‚'] = result['åœ°å€'].str.split('-').str[0]
        
        # åˆå§‹åŒ–ç›¸å°é¢¨éšªæ¬„ä½
        result['ç›¸å°é¢¨éšªç­‰ç´š'] = 'ğŸŸ¢ ä½é¢¨éšª'
        result['ç¸£å¸‚å…§æ’å'] = 0
        result['ç¸£å¸‚å…§ç™¾åˆ†ä½'] = 0.0
        result['ç›¸å°é¢¨éšªåŸå› '] = ''
        
        # ç›¸å°åˆ†ç´šé–¾å€¼
        high_risk_threshold = 25
        medium_risk_threshold = 50
        
        # çµ•å°æœ€ä½æ¨™æº–
        absolute_minimums = {
            'min_transactions': 1,
            'min_time_adj_rate': 0.005,
            'max_sales_months': 60
        }
        
        # æŒ‰ç¸£å¸‚åˆ†åˆ¥é€²è¡Œç›¸å°åˆ†ç´š
        for city in result['ç¸£å¸‚'].unique():
            city_mask = result['ç¸£å¸‚'] == city
            city_data = result[city_mask].copy()
            
            if len(city_data) < 3:
                print(f"      âš ï¸ {city} è¡Œæ”¿å€æ•¸é‡éå°‘({len(city_data)})ï¼Œä¿æŒçµ•å°åˆ†ç´š")
                result.loc[city_mask, 'ç›¸å°é¢¨éšªç­‰ç´š'] = result.loc[city_mask, 'çµ•å°é¢¨éšªç­‰ç´š']
                result.loc[city_mask, 'ç›¸å°é¢¨éšªåŸå› '] = 'è¡Œæ”¿å€æ•¸é‡ä¸è¶³,ä½¿ç”¨çµ•å°æ¨™æº–'
                continue
            
            # è¨ˆç®—ç¸£å¸‚å…§ç¶œåˆæ’å
            time_adj_rank = city_data['æ™‚é–“èª¿æ•´å»åŒ–ç‡'].rank(method='min', ascending=False)
            monthly_rank = city_data['æœˆå»åŒ–ç‡'].rank(method='min', ascending=False)
            transaction_rank = city_data['æˆäº¤ç­†æ•¸'].rank(method='min', ascending=False)
            
            # ç¶œåˆæ’åï¼ˆæ¬Šé‡åˆ†é…ï¼‰
            composite_rank = (time_adj_rank * 0.4 + monthly_rank * 0.3 + transaction_rank * 0.3)
            
            # è¨ˆç®—ç™¾åˆ†ä½æ•¸
            percentiles = composite_rank.rank(pct=True) * 100
            
            # ç›¸å°é¢¨éšªåˆ†ç´š
            relative_risks = []
            relative_reasons = []
            
            for i, (orig_idx, row) in enumerate(city_data.iterrows()):
                percentile = percentiles.iloc[i]
                
                # æª¢æŸ¥çµ•å°æœ€ä½æ¨™æº–
                absolute_issues = []
                if row.get('æˆäº¤ç­†æ•¸', 0) < absolute_minimums['min_transactions']:
                    absolute_issues.append('æˆäº¤ç­†æ•¸éä½')
                if row.get('æ™‚é–“èª¿æ•´å»åŒ–ç‡', 0) < absolute_minimums['min_time_adj_rate']:
                    absolute_issues.append('å»åŒ–ç‡æ¥µä½')
                if row.get('å¹³å‡éŠ·å”®æœˆæ•¸', 0) > absolute_minimums['max_sales_months']:
                    absolute_issues.append('éŠ·å”®æœŸé–“éé•·')
                
                if absolute_issues:
                    risk_level = 'ğŸ”´ é«˜é¢¨éšª'
                    reason = f"çµ•å°æ¨™æº–å•é¡Œ: {'; '.join(absolute_issues)}"
                else:
                    # ä½¿ç”¨ç›¸å°æ¨™æº–
                    if percentile <= high_risk_threshold:
                        risk_level = 'ğŸ”´ é«˜é¢¨éšª'
                        reason = f"ç¸£å¸‚å…§æ’åå¾Œ{high_risk_threshold}% (ç¬¬{composite_rank.iloc[i]:.0f}å)"
                    elif percentile <= medium_risk_threshold:
                        risk_level = 'ğŸŸ¡ ä¸­é¢¨éšª'
                        reason = f"ç¸£å¸‚å…§ä¸­ç­‰è¡¨ç¾ (ç¬¬{composite_rank.iloc[i]:.0f}å)"
                    else:
                        risk_level = 'ğŸŸ¢ ä½é¢¨éšª'
                        reason = f"ç¸£å¸‚å…§å‰{100-medium_risk_threshold}% (ç¬¬{composite_rank.iloc[i]:.0f}å)"
                
                relative_risks.append(risk_level)
                relative_reasons.append(reason)
            
            # æ›´æ–°çµæœ
            result.loc[city_mask, 'ç›¸å°é¢¨éšªç­‰ç´š'] = relative_risks
            result.loc[city_mask, 'ç¸£å¸‚å…§æ’å'] = composite_rank.values
            result.loc[city_mask, 'ç¸£å¸‚å…§ç™¾åˆ†ä½'] = percentiles.values
            result.loc[city_mask, 'ç›¸å°é¢¨éšªåŸå› '] = relative_reasons
            
            # é¡¯ç¤ºè©²ç¸£å¸‚çš„åˆ†ç´šçµæœ
            city_risk_counts = pd.Series(relative_risks).value_counts()
            print(f"      ğŸ™ï¸ {city} ç›¸å°åˆ†ç´šçµæœ:")
            for level, count in city_risk_counts.items():
                percentage = count / len(city_data) * 100
                print(f"         {level}: {count} å€‹ ({percentage:.1f}%)")
        
        # ä½¿ç”¨ç›¸å°é¢¨éšªç­‰ç´šä½œç‚ºä¸»è¦é¢¨éšªç­‰ç´š
        result['é¢¨éšªç­‰ç´š'] = result['ç›¸å°é¢¨éšªç­‰ç´š']
        
        return result
    
    def run_interactive_analysis(self):
        """åŸ·è¡Œäº’å‹•å¼åˆ†æç•Œé¢"""
        print("ğŸ–¥ï¸ å•Ÿå‹•æ™‚é–“èª¿æ•´äº’å‹•å¼åˆ†æç•Œé¢...")
        
        if self.sale_data is None or self.transaction_data is None:
            print("âŒ è«‹å…ˆè¼‰å…¥æ•¸æ“š")
            return
        
        while True:
            print("\n" + "="*55)
            print("ğŸ  é å”®å±‹é¢¨éšªæª¢è¦–åˆ†æç³»çµ± (ä¿®æ­£ç‰ˆ)")
            print("="*55)
            print("1. ğŸ“Š æ™‚é–“èª¿æ•´æ•´é«”å¸‚å ´é¢¨éšªåˆ†æ")
            print("2. ğŸ™ï¸ æŒ‡å®šç¸£å¸‚æ™‚é–“èª¿æ•´åˆ†æ")
            print("3. ğŸ¯ çµ•å° vs ç›¸å°é¢¨éšªåˆ†ç´šæ¯”è¼ƒ")
            print("4. ğŸ“‹ ç”Ÿæˆåˆ†æå ±å‘Š")
            print("0. âŒ é€€å‡ºç³»çµ±")
            print("="*55)
            
            choice = input("è«‹é¸æ“‡åŠŸèƒ½ (0-4): ").strip()
            
            if choice == '0':
                print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ï¼Œå†è¦‹ï¼")
                break
            elif choice == '1':
                self._show_overall_analysis()
            elif choice == '2':
                self._show_city_analysis()
            elif choice == '3':
                self._show_risk_comparison()
            elif choice == '4':
                self._generate_report()
            else:
                print("âš ï¸ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
    
    def _show_overall_analysis(self):
        """é¡¯ç¤ºæ•´é«”åˆ†æ"""
        print("\nğŸ“Š æ™‚é–“èª¿æ•´æ•´é«”å¸‚å ´é¢¨éšªåˆ†æ")
        print("-" * 35)
        
        print("è«‹é¸æ“‡é¢¨éšªåˆ†ç´šæ–¹å¼:")
        print("1. ç›¸å°åˆ†ç´š (åŒç¸£å¸‚å…§æ¯”è¼ƒï¼Œæ¨è–¦)")
        print("2. çµ•å°åˆ†ç´š (å›ºå®šé–¾å€¼)")
        
        choice = input("è«‹é¸æ“‡ (1-2): ").strip()
        use_relative = choice == '1'
        
        # è¨ˆç®—æ™‚é–“èª¿æ•´å»åŒ–ç‡
        absorption_data = self.calculate_time_adjusted_absorption_rate(by_quarter=True)
        
        # é€²è¡Œé¢¨éšªåˆ†ç´š
        risk_analysis = self.classify_risk_with_relative_option(absorption_data, use_relative)
        
        # çµ±è¨ˆçµæœ
        classification_method = 'ç›¸å°åˆ†ç´š' if use_relative else 'çµ•å°åˆ†ç´š'
        print(f"\nğŸ¯ æ™‚é–“èª¿æ•´åˆ†ææ‘˜è¦ ({classification_method}):")
        
        total_regions = len(risk_analysis['åœ°å€'].unique())
        high_risk = len(risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸ”´ é«˜é¢¨éšª'])
        medium_risk = len(risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸŸ¡ ä¸­é¢¨éšª'])
        low_risk = len(risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸŸ¢ ä½é¢¨éšª'])
        
        print(f"   ç¸½åˆ†æåœ°å€æ•¸: {total_regions}")
        print(f"   ğŸ”´ é«˜é¢¨éšªåœ°å€: {high_risk} å€‹ ({high_risk/total_regions*100:.1f}%)")
        print(f"   ğŸŸ¡ ä¸­é¢¨éšªåœ°å€: {medium_risk} å€‹ ({medium_risk/total_regions*100:.1f}%)")
        print(f"   ğŸŸ¢ ä½é¢¨éšªåœ°å€: {low_risk} å€‹ ({low_risk/total_regions*100:.1f}%)")
        print(f"   ğŸ“ˆ å¹³å‡æ™‚é–“èª¿æ•´å»åŒ–ç‡: {risk_analysis['æ™‚é–“èª¿æ•´å»åŒ–ç‡'].mean():.2%}")
        print(f"   â° å¹³å‡æœˆå»åŒ–ç‡: {risk_analysis['æœˆå»åŒ–ç‡'].mean():.3%}")
        
        # é¡¯ç¤ºé«˜é¢¨éšªåœ°å€
        high_risk_areas = risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸ”´ é«˜é¢¨éšª']['åœ°å€'].unique()
        if len(high_risk_areas) > 0:
            print(f"\nâš ï¸ é«˜é¢¨éšªåœ°å€æ¸…å–® (å‰10å€‹):")
            for area in high_risk_areas[:10]:
                print(f"   â€¢ {area}")
        else:
            print(f"\nâœ… ç›®å‰ç„¡é«˜é¢¨éšªåœ°å€")
        
        # å¦‚æœæ˜¯ç›¸å°åˆ†ç´šï¼Œé¡¯ç¤ºå„ç¸£å¸‚æ”¹å–„æƒ…æ³
        if use_relative and 'ç¸£å¸‚' in risk_analysis.columns:
            print(f"\nğŸ™ï¸ å„ç¸£å¸‚é¢¨éšªåˆ†å¸ƒ:")
            city_stats = risk_analysis.groupby('ç¸£å¸‚').agg({
                'é¢¨éšªç­‰ç´š': lambda x: (x == 'ğŸ”´ é«˜é¢¨éšª').sum(),
                'åœ°å€': 'count'
            }).reset_index()
            city_stats.columns = ['ç¸£å¸‚', 'é«˜é¢¨éšªåœ°å€æ•¸', 'ç¸½åœ°å€æ•¸']
            
            for _, row in city_stats.iterrows():
                risk_rate = row['é«˜é¢¨éšªåœ°å€æ•¸'] / row['ç¸½åœ°å€æ•¸'] * 100
                print(f"   {row['ç¸£å¸‚']}: {row['é«˜é¢¨éšªåœ°å€æ•¸']}/{row['ç¸½åœ°å€æ•¸']} é«˜é¢¨éšª ({risk_rate:.1f}%)")
    
    def _show_city_analysis(self):
        """é¡¯ç¤ºç¸£å¸‚åˆ†æ"""
        print("\nğŸ™ï¸ æŒ‡å®šç¸£å¸‚æ™‚é–“èª¿æ•´åˆ†æ")
        print("-" * 35)
        
        available_cities = sorted(self.sale_data['ç¸£å¸‚'].unique())
        print("å¯ç”¨ç¸£å¸‚:")
        for i, city in enumerate(available_cities, 1):
            print(f"{i:2d}. {city}")
        
        try:
            choice = int(input("\nè«‹é¸æ“‡ç¸£å¸‚ç·¨è™Ÿ: ")) - 1
            if 0 <= choice < len(available_cities):
                selected_city = available_cities[choice]
                
                # è¨ˆç®—è©²ç¸£å¸‚çš„åˆ†æ
                absorption_data = self.calculate_time_adjusted_absorption_rate(by_quarter=True)
                
                # ç¯©é¸è©²ç¸£å¸‚æ•¸æ“š
                city_data = absorption_data[absorption_data['åœ°å€'].str.startswith(f"{selected_city}-")]
                
                if len(city_data) > 0:
                    # é€²è¡Œç›¸å°é¢¨éšªåˆ†ç´š
                    risk_analysis = self.classify_risk_with_relative_option(city_data, use_relative=True)
                    
                    print(f"\nğŸ“Š {selected_city} æ™‚é–“èª¿æ•´åˆ†æçµæœ:")
                    
                    total_districts = len(risk_analysis['åœ°å€'].unique())
                    high_risk = len(risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸ”´ é«˜é¢¨éšª'])
                    medium_risk = len(risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸŸ¡ ä¸­é¢¨éšª'])
                    low_risk = len(risk_analysis[risk_analysis['é¢¨éšªç­‰ç´š'] == 'ğŸŸ¢ ä½é¢¨éšª'])
                    
                    print(f"   è¡Œæ”¿å€æ•¸é‡: {total_districts}")
                    print(f"   ğŸ”´ é«˜é¢¨éšª: {high_risk} å€‹")
                    print(f"   ğŸŸ¡ ä¸­é¢¨éšª: {medium_risk} å€‹")
                    print(f"   ğŸŸ¢ ä½é¢¨éšª: {low_risk} å€‹")
                    print(f"   å¹³å‡æ™‚é–“èª¿æ•´å»åŒ–ç‡: {risk_analysis['æ™‚é–“èª¿æ•´å»åŒ–ç‡'].mean():.2%}")
                    
                    # é¡¯ç¤ºå„è¡Œæ”¿å€æ’å
                    print(f"\nğŸ“‹ {selected_city} å„è¡Œæ”¿å€é¢¨éšªæ’å:")
                    
                    district_summary = risk_analysis.groupby('åœ°å€').agg({
                        'æ™‚é–“èª¿æ•´å»åŒ–ç‡': 'mean',
                        'æœˆå»åŒ–ç‡': 'mean',
                        'é¢¨éšªç­‰ç´š': lambda x: x.mode().iloc[0] if len(x) > 0 else 'ğŸŸ¢ ä½é¢¨éšª',
                        'ç›¸å°é¢¨éšªåŸå› ': 'first'
                    }).reset_index()
                    
                    # æŒ‰æ™‚é–“èª¿æ•´å»åŒ–ç‡æ’åº
                    district_summary = district_summary.sort_values('æ™‚é–“èª¿æ•´å»åŒ–ç‡', ascending=False)
                    
                    for _, row in district_summary.iterrows():
                        district_name = row['åœ°å€'].split('-')[1]
                        reason = row.get('ç›¸å°é¢¨éšªåŸå› ', '')
                        print(f"   {row['é¢¨éšªç­‰ç´š']} {district_name}: æ™‚é–“èª¿æ•´å»åŒ–ç‡ {row['æ™‚é–“èª¿æ•´å»åŒ–ç‡']:.2%} ({reason})")
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ° {selected_city} çš„æ•¸æ“š")
            else:
                print("âš ï¸ ç„¡æ•ˆçš„ç¸£å¸‚ç·¨è™Ÿ")
        except (ValueError, IndexError):
            print("âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
    
    def _show_risk_comparison(self):
        """é¡¯ç¤ºçµ•å°vsç›¸å°é¢¨éšªåˆ†ç´šæ¯”è¼ƒ"""
        print("\nğŸ¯ çµ•å° vs ç›¸å°é¢¨éšªåˆ†ç´šæ¯”è¼ƒ")
        print("-" * 45)
        
        # è¨ˆç®—çµ•å°åˆ†ç´š
        absorption_data_abs = self.calculate_time_adjusted_absorption_rate(by_quarter=True)
        absolute_result = self.classify_risk_with_relative_option(absorption_data_abs, use_relative=False)
        
        # è¨ˆç®—ç›¸å°åˆ†ç´š
        absorption_data_rel = self.calculate_time_adjusted_absorption_rate(by_quarter=True)
        relative_result = self.classify_risk_with_relative_option(absorption_data_rel, use_relative=True)
        
        # çµ±è¨ˆæ¯”è¼ƒ
        print(f"\nğŸ“Š åˆ†ç´šçµæœçµ±è¨ˆæ¯”è¼ƒ:")
        
        # çµ•å°åˆ†ç´šçµ±è¨ˆ
        abs_counts = absolute_result['é¢¨éšªç­‰ç´š'].value_counts()
        print(f"\nğŸ”¸ çµ•å°åˆ†ç´šçµæœ:")
        for level, count in abs_counts.items():
            percentage = count / len(absolute_result) * 100
            print(f"   {level}: {count} å€‹åœ°å€ ({percentage:.1f}%)")
        
        # ç›¸å°åˆ†ç´šçµ±è¨ˆ
        rel_counts = relative_result['é¢¨éšªç­‰ç´š'].value_counts()
        print(f"\nğŸ”¸ ç›¸å°åˆ†ç´šçµæœ:")
        for level, count in rel_counts.items():
            percentage = count / len(relative_result) * 100
            print(f"   {level}: {count} å€‹åœ°å€ ({percentage:.1f}%)")
        
        # æ”¹å–„çµ±è¨ˆ
        abs_high = len(absolute_result[absolute_result['é¢¨éšªç­‰ç´š'] == 'ğŸ”´ é«˜é¢¨éšª'])
        rel_high = len(relative_result[relative_result['é¢¨éšªç­‰ç´š'] == 'ğŸ”´ é«˜é¢¨éšª'])
        improvement = abs_high - rel_high
        
        print(f"\nğŸ’¡ ç›¸å°åˆ†ç´šæ”¹å–„æ•ˆæœ:")
        print(f"   çµ•å°åˆ†ç´šé«˜é¢¨éšªåœ°å€: {abs_high} å€‹")
        print(f"   ç›¸å°åˆ†ç´šé«˜é¢¨éšªåœ°å€: {rel_high} å€‹")
        print(f"   æ”¹å–„åœ°å€æ•¸: {improvement} å€‹")
        print(f"   æ”¹å–„æ¯”ä¾‹: {improvement/len(relative_result)*100:.1f}%")
    
    def _generate_report(self):
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆåˆ†æå ±å‘Š")
        print("-" * 25)
        
        # è¨ˆç®—ç›¸å°åˆ†ç´šçµæœ
        absorption_data = self.calculate_time_adjusted_absorption_rate(by_quarter=True)
        risk_analysis = self.classify_risk_with_relative_option(absorption_data, use_relative=True)
        
        # å„²å­˜çµæœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f'é å”®å±‹é¢¨éšªåˆ†æå ±å‘Š_{timestamp}.csv'
        
        risk_analysis.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"âœ… åˆ†æå ±å‘Šå·²å„²å­˜: {output_file}")
        print(f"   ğŸ“Š åˆ†æåœ°å€æ•¸: {len(risk_analysis['åœ°å€'].unique())}")
        print(f"   ğŸ“… åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    print("ğŸ  é å”®å±‹é¢¨éšªæª¢è¦–åˆ†æç³»çµ± (ä¿®æ­£ç‰ˆ)")
    print("=" * 50)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = WorkingPreSaleRiskAnalyzer()
    
    # è¼‰å…¥æ•¸æ“š
    input_dir = r"C:\pylabs\area-risk-flagging\data\lvr_moi\pre_sale_data\processed"
    fn = "é å”®å±‹è²·è³£ä¸»æª”_11006_11406.csv"
    transaction_file = os.path.join(input_dir, fn)

    input_dir = r"C:\pylabs\area-risk-flagging\data\lvr_moi\sale_data\processed"
    fn = "é å”®å±‹å‚™æŸ¥.csv"
    sale_file = os.path.join(input_dir, fn)
    
    # è¼‰å…¥æ•¸æ“š
    if analyzer.load_data(sale_file, transaction_file):
        print("âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œå•Ÿå‹•äº’å‹•å¼åˆ†æ...")
        analyzer.run_interactive_analysis()
    else:
        print("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆè·¯å¾‘")

if __name__ == "__main__":
    main()


