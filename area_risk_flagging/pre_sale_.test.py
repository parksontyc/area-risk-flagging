"""
é å”®å±‹å¸‚å ´å»åŒ–ç‡åˆ†æç¨‹å¼ (å«ç¸£å¸‚è¡Œæ”¿å€æ·±åº¦åˆ†æ)
è€ƒæ…®éŠ·å”®æ™‚é–“å› ç´ çš„é€²éšåˆ†æ

åŠŸèƒ½ç‰¹è‰²ï¼š
âœ… åŸºæ–¼å‚™æŸ¥ç·¨è™Ÿç²¾ç¢ºæ¯”å°
âœ… æ™‚é–“èª¿æ•´å»åŒ–ç‡è¨ˆç®—  
âœ… ç¸£å¸‚å¸‚å ´ç†±åº¦åˆ†æ
âœ… è¡Œæ”¿å€è¡¨ç¾ç­‰ç´šè©•ä¼°
âœ… è©³ç´°ç¸£å¸‚åˆ†æå ±å‘Š
âœ… è¡Œæ”¿å€å­£åº¦æ’åè¶¨å‹¢
âœ… å„è¡Œæ”¿å€ç¤¾å€å»åŒ–é«˜ä½æ’å
âœ… å¤šç¶­åº¦è¦–è¦ºåŒ–åœ–è¡¨
âœ… è¡Œæ”¿å€å»åŒ–ç‡ç†±åŠ›åœ–
âœ… ç¸£å¸‚å°ˆå±¬è¦–è¦ºåŒ–åœ–è¡¨

åˆ†æå±¤ç´šï¼š
ğŸ“Š å¸‚å ´ç¸½è¦½ â†’ ç¸£å¸‚åˆ†æ â†’ è¡Œæ”¿å€åˆ†æ â†’ ç¤¾å€æ’å
ğŸ” åŒ…å«å­£åº¦è¶¨å‹¢ã€è¡¨ç¾æ’åã€æŠ•è³‡å»ºè­°

å¿…è¦å¥—ä»¶ï¼š
pip install pandas numpy matplotlib seaborn

å¯é¸å¥—ä»¶ï¼ˆåŒ¯å‡ºExcelæ ¼å¼ï¼‰ï¼š
pip install openpyxl

ä½¿ç”¨æ–¹æ³•ï¼š
python presale_analysis.py
"""
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

import sys
from pathlib import Path
project_root = Path.cwd().parent  # æ‰¾å‡ºæ ¹ç›®éŒ„ï¼šPath.cwd()æ‰¾å‡ºç¾åœ¨æ‰€åœ¨ç›®éŒ„(/run).parent(ä¸Šä¸€å±¤æ˜¯notebook).parent(å†ä¸Šå±¤ä¸€å±¤business_district_discovery)
print(project_root)
sys.path.append(str(project_root))
from matplotlib.font_manager import fontManager
import matplotlib as mlp
font_path = Path(project_root) / "utils" / "ChineseFont.ttf"
fontManager.addfont(str(font_path))
mlp.rc('font', family="ChineseFont")

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class PresaleMarketAnalysis:
    def __init__(self, analysis_date=None):
        self.transaction_data = None
        self.community_data = None
        self.analysis_result = None
        # å…è¨±ä½¿ç”¨è€…æŒ‡å®šåˆ†æåŸºæº–æ—¥æœŸï¼Œé è¨­ç‚º 2024å¹´åº•
        if analysis_date:
            self.current_date = analysis_date
        else:
            self.current_date = datetime(2024, 12, 31)  # ä½¿ç”¨å›ºå®šæ—¥æœŸé¿å…æ™‚é–“è®Šå‹•å½±éŸ¿
        print(f"åˆ†æåŸºæº–æ—¥æœŸè¨­å®šç‚º: {self.current_date.strftime('%Y-%m-%d')}")
        
    def load_data(self, transaction_file, community_file):
        """è¼‰å…¥äº¤æ˜“è³‡æ–™å’Œç¤¾å€è³‡æ–™"""
        print("æ­£åœ¨è¼‰å…¥è³‡æ–™...")
        print("ğŸ“‹ åˆ†æç­–ç•¥ï¼šåƒ…åˆ†æåœ¨å…©å€‹æª”æ¡ˆä¸­éƒ½æœ‰å°æ‡‰ç·¨è™Ÿçš„ç¤¾å€")
        print("   â€¢ äº¤æ˜“æª”æ¡ˆçš„ 'å‚™æŸ¥ç·¨è™Ÿ' æ¬„ä½")
        print("   â€¢ ç¤¾å€æª”æ¡ˆçš„ 'ç·¨è™Ÿ' æ¬„ä½")
        print("   â€¢ ç¢ºä¿è³‡æ–™å®Œæ•´æ€§å’Œåˆ†ææº–ç¢ºæ€§")
        
        # è¼‰å…¥é å”®å±‹äº¤æ˜“è³‡æ–™
        self.transaction_data = pd.read_csv(transaction_file)
        print(f"âœ… äº¤æ˜“è³‡æ–™è¼‰å…¥å®Œæˆ: {len(self.transaction_data)} ç­†è¨˜éŒ„")
        
        # è¼‰å…¥ç¤¾å€é å”®å‚™æŸ¥è³‡æ–™
        self.community_data = pd.read_csv(community_file)
        print(f"âœ… ç¤¾å€è³‡æ–™è¼‰å…¥å®Œæˆ: {len(self.community_data)} å€‹ç¤¾å€")
        
        return self
    
    def parse_date_columns(self):
        """è§£ææ—¥æœŸç›¸é—œæ¬„ä½"""
        print("æ­£åœ¨è§£ææ—¥æœŸè³‡æ–™...")
        
        # è™•ç†ç¤¾å€è³‡æ–™çš„æ—¥æœŸæ¬„ä½
        date_columns = ['éŠ·å”®èµ·å§‹æ™‚é–“', 'è‡ªå”®èµ·å§‹æ™‚é–“', 'ä»£éŠ·èµ·å§‹æ™‚é–“', 'å‚™æŸ¥å®Œæˆæ—¥æœŸ', 'å»ºç…§æ ¸ç™¼æ—¥']
        
        for col in date_columns:
            if col in self.community_data.columns:
                # å°‡æ•¸å€¼å‹æ—¥æœŸè½‰æ›ç‚ºdatetime (å‡è¨­æ˜¯æ°‘åœ‹å¹´æ ¼å¼)
                self.community_data[col] = pd.to_numeric(self.community_data[col], errors='coerce')
                # è™•ç†æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´ (ä¾‹å¦‚: 1120101 -> 2023-01-01)
                self.community_data[f'{col}_date'] = self.community_data[col].apply(self.convert_taiwan_date)
        
        # è™•ç†äº¤æ˜“è³‡æ–™çš„æ—¥æœŸ
        if 'äº¤æ˜“å¹´æœˆ' in self.transaction_data.columns:
            self.transaction_data['äº¤æ˜“å¹´æœˆ'] = pd.to_numeric(self.transaction_data['äº¤æ˜“å¹´æœˆ'], errors='coerce')
            self.transaction_data['äº¤æ˜“æ—¥æœŸ_parsed'] = self.transaction_data['äº¤æ˜“å¹´æœˆ'].apply(self.convert_taiwan_yearmonth)
        
        print("æ—¥æœŸè§£æå®Œæˆ")
        return self
    # è«‹å°‡ä»¥ä¸‹æ–¹æ³•æ·»åŠ åˆ°æ‚¨çš„ PresaleMarketAnalysis é¡åˆ¥ä¸­

    def analyze_quarterly_trends(self):
        """åˆ†æå­£åº¦è¶¨å‹¢"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return None
        
        print("æ­£åœ¨åˆ†æå­£åº¦è¶¨å‹¢...")
        
        # è™•ç†äº¤æ˜“å¹´å­£è³‡æ–™
        if 'äº¤æ˜“å¹´å­£' not in self.transaction_data.columns:
            print("âš ï¸ äº¤æ˜“è³‡æ–™ä¸­ç¼ºå°‘ 'äº¤æ˜“å¹´å­£' æ¬„ä½ï¼Œç„¡æ³•é€²è¡Œå­£åº¦åˆ†æ")
            return None
        
        # æ¸…ç†äº¤æ˜“å¹´å­£è³‡æ–™
        transaction_quarterly = self.transaction_data.dropna(subset=['äº¤æ˜“å¹´å­£', 'å‚™æŸ¥ç·¨è™Ÿ'])
        
        # è¨ˆç®—æ¯å­£æ¯å€‹ç¤¾å€çš„éŠ·å”®æˆ¶æ•¸
        quarterly_sales = transaction_quarterly.groupby(['å‚™æŸ¥ç·¨è™Ÿ', 'äº¤æ˜“å¹´å­£']).size().reset_index(name='å­£åº¦éŠ·å”®æˆ¶æ•¸')
        
        # èˆ‡ç¤¾å€åŸºæœ¬è³‡æ–™åˆä½µ
        community_with_id = self.community_data.dropna(subset=['ç·¨è™Ÿ'])
        community_with_id['ç·¨è™Ÿ'] = community_with_id['ç·¨è™Ÿ'].astype(str)
        quarterly_sales['å‚™æŸ¥ç·¨è™Ÿ'] = quarterly_sales['å‚™æŸ¥ç·¨è™Ÿ'].astype(str)
        
        quarterly_analysis = pd.merge(
            quarterly_sales,
            community_with_id[['ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¤¾å€åç¨±', 'æˆ¶æ•¸']],
            left_on='å‚™æŸ¥ç·¨è™Ÿ',
            right_on='ç·¨è™Ÿ',
            how='inner'
        )
        
        # è¨ˆç®—ç´¯ç©éŠ·å”®å’Œå»åŒ–ç‡
        quarterly_analysis = quarterly_analysis.sort_values(['å‚™æŸ¥ç·¨è™Ÿ', 'äº¤æ˜“å¹´å­£'])
        quarterly_analysis['ç´¯ç©éŠ·å”®æˆ¶æ•¸'] = quarterly_analysis.groupby('å‚™æŸ¥ç·¨è™Ÿ')['å­£åº¦éŠ·å”®æˆ¶æ•¸'].cumsum()
        quarterly_analysis['ç´¯ç©å»åŒ–ç‡'] = (quarterly_analysis['ç´¯ç©éŠ·å”®æˆ¶æ•¸'] / quarterly_analysis['æˆ¶æ•¸']) * 100
        quarterly_analysis['ç´¯ç©å»åŒ–ç‡'] = quarterly_analysis['ç´¯ç©å»åŒ–ç‡'].round(2)
        
        self.quarterly_analysis = quarterly_analysis
        print(f"âœ… å­£åº¦è¶¨å‹¢åˆ†æå®Œæˆ")
        return quarterly_analysis

    def analyze_city_detailed(self, city_name=None):
        """è©³ç´°åˆ†æç‰¹å®šç¸£å¸‚æˆ–æ‰€æœ‰ç¸£å¸‚"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return
        
        if not hasattr(self, 'quarterly_analysis'):
            print("æ­£åœ¨é€²è¡Œå­£åº¦åˆ†æ...")
            self.analyze_quarterly_trends()
        
        cities_to_analyze = [city_name] if city_name else self.analysis_result['ç¸£å¸‚'].unique()
        
        self.city_detailed_analysis = {}
        
        for city in cities_to_analyze:
            if pd.isna(city):
                continue
                
            print(f"\næ­£åœ¨åˆ†æ {city}...")
            
            # ç¯©é¸è©²ç¸£å¸‚çš„è³‡æ–™
            city_data = self.analysis_result[self.analysis_result['ç¸£å¸‚'] == city].copy()
            city_quarterly = None
            if hasattr(self, 'quarterly_analysis') and self.quarterly_analysis is not None:
                city_quarterly = self.quarterly_analysis[self.quarterly_analysis['ç¸£å¸‚'] == city].copy()
            
            # è¡Œæ”¿å€å±¤ç´šåˆ†æ
            district_analysis = city_data.groupby('è¡Œæ”¿å€').agg({
                'æˆ¶æ•¸': 'sum',
                'å·²å”®æˆ¶æ•¸': 'sum',
                'å»åŒ–ç‡': 'mean',
                'æœˆå‡å»åŒ–ç‡': 'mean',
                'éŠ·å”®å¤©æ•¸': 'mean'
            }).reset_index()
            
            district_analysis['æ•´é«”å»åŒ–ç‡'] = (district_analysis['å·²å”®æˆ¶æ•¸'] / district_analysis['æˆ¶æ•¸']) * 100
            district_analysis['æ•´é«”å»åŒ–ç‡'] = district_analysis['æ•´é«”å»åŒ–ç‡'].round(2)
            district_analysis['ç¤¾å€æ•¸é‡'] = city_data.groupby('è¡Œæ”¿å€').size().values
            district_analysis = district_analysis.sort_values('æ•´é«”å»åŒ–ç‡', ascending=False)
            
            # å„è¡Œæ”¿å€çš„å­£åº¦æ’åï¼ˆå¦‚æœæœ‰å­£åº¦è³‡æ–™ï¼‰
            quarterly_district_ranking = None
            if city_quarterly is not None and len(city_quarterly) > 0:
                # è¨ˆç®—å„å­£å„è¡Œæ”¿å€çš„å¹³å‡å»åŒ–ç‡
                quarterly_district = city_quarterly.groupby(['äº¤æ˜“å¹´å­£', 'è¡Œæ”¿å€'])['ç´¯ç©å»åŒ–ç‡'].mean().reset_index()
                quarterly_district_ranking = quarterly_district.pivot(index='è¡Œæ”¿å€', columns='äº¤æ˜“å¹´å­£', values='ç´¯ç©å»åŒ–ç‡')
                
                # ç‚ºæ¯å­£æ·»åŠ æ’å
                for quarter in quarterly_district_ranking.columns:
                    quarterly_district_ranking[f'{quarter}_æ’å'] = quarterly_district_ranking[quarter].rank(ascending=False)
            
            # å„è¡Œæ”¿å€å…§ç¤¾å€å»åŒ–ç‡æ’å
            district_community_ranking = {}
            for district in city_data['è¡Œæ”¿å€'].unique():
                if pd.isna(district):
                    continue
                    
                district_communities = city_data[city_data['è¡Œæ”¿å€'] == district].copy()
                district_communities = district_communities.sort_values('å»åŒ–ç‡', ascending=False)
                
                # å»åŒ–é«˜çš„ç¤¾å€ï¼ˆå‰5åæˆ–å»åŒ–ç‡>60%ï¼‰
                high_performing = district_communities[
                    (district_communities['å»åŒ–ç‡'] > 60) | 
                    (district_communities.index.isin(district_communities.head(5).index))
                ]
                
                # å»åŒ–ä½çš„ç¤¾å€ï¼ˆå¾Œ5åæˆ–å»åŒ–ç‡<30%ï¼‰
                low_performing = district_communities[
                    (district_communities['å»åŒ–ç‡'] < 30) | 
                    (district_communities.index.isin(district_communities.tail(5).index))
                ].sort_values('å»åŒ–ç‡')
                
                district_community_ranking[district] = {
                    'high_performing': high_performing,
                    'low_performing': low_performing,
                    'total_communities': len(district_communities)
                }
            
            # å„²å­˜è©²ç¸£å¸‚çš„åˆ†æçµæœ
            self.city_detailed_analysis[city] = {
                'basic_stats': {
                    'total_communities': len(city_data),
                    'total_units': city_data['æˆ¶æ•¸'].sum(),
                    'sold_units': city_data['å·²å”®æˆ¶æ•¸'].sum(),
                    'overall_absorption_rate': (city_data['å·²å”®æˆ¶æ•¸'].sum() / city_data['æˆ¶æ•¸'].sum()) * 100,
                    'avg_monthly_rate': city_data['æœˆå‡å»åŒ–ç‡'].mean(),
                    'districts_count': len(city_data['è¡Œæ”¿å€'].unique())
                },
                'district_analysis': district_analysis,
                'quarterly_district_ranking': quarterly_district_ranking,
                'district_community_ranking': district_community_ranking
            }
        
        print(f"âœ… å®Œæˆ {len(cities_to_analyze)} å€‹ç¸£å¸‚çš„è©³ç´°åˆ†æ")
        return self.city_detailed_analysis

    def generate_city_detailed_report(self, city_name=None):
        """ç”Ÿæˆè©³ç´°çš„ç¸£å¸‚åˆ†æå ±å‘Š"""
        if not hasattr(self, 'city_detailed_analysis'):
            print("è«‹å…ˆåŸ·è¡Œè©³ç´°ç¸£å¸‚åˆ†æ")
            return
        
        cities_to_report = [city_name] if city_name else list(self.city_detailed_analysis.keys())
        
        for city in cities_to_report:
            if city not in self.city_detailed_analysis:
                print(f"âŒ æ‰¾ä¸åˆ° {city} çš„åˆ†æè³‡æ–™")
                continue
            
            analysis = self.city_detailed_analysis[city]
            
            print("\n" + "="*80)
            print(f"ğŸ™ï¸ {city} è©³ç´°å¸‚å ´åˆ†æå ±å‘Š")
            print("="*80)
            
            # åŸºæœ¬æ¦‚æ³
            stats = analysis['basic_stats']
            print(f"\nğŸ“Š {city} å¸‚å ´åŸºæœ¬æ¦‚æ³")
            print(f"è¡Œæ”¿å€æ•¸é‡: {stats['districts_count']} å€‹")
            print(f"ç¤¾å€ç¸½æ•¸: {stats['total_communities']} å€‹")
            print(f"ç¸½æˆ¶æ•¸: {stats['total_units']:,} æˆ¶")
            print(f"å·²å”®æˆ¶æ•¸: {stats['sold_units']:,} æˆ¶")
            print(f"æ•´é«”å»åŒ–ç‡: {stats['overall_absorption_rate']:.2f}%")
            print(f"å¹³å‡æœˆå»åŒ–ç‡: {stats['avg_monthly_rate']:.2f}%")
            
            # è¡Œæ”¿å€æ’å
            district_analysis = analysis['district_analysis']
            print(f"\nğŸ˜ï¸ {city} è¡Œæ”¿å€å»åŒ–ç‡æ’å")
            print(f"{'æ’å':<4} {'è¡Œæ”¿å€':<12} {'æ•´é«”å»åŒ–ç‡':<10} {'ç¤¾å€æ•¸':<6} {'ç¸½æˆ¶æ•¸':<8} {'å·²å”®æˆ¶æ•¸':<8} {'æœˆå‡å»åŒ–ç‡':<10}")
            print("-" * 75)
            
            for idx, row in district_analysis.iterrows():
                rank = district_analysis.index.get_loc(idx) + 1
                print(f"{rank:<4} {row['è¡Œæ”¿å€']:<12} {row['æ•´é«”å»åŒ–ç‡']:<10.1f}% "
                    f"{row['ç¤¾å€æ•¸é‡']:<6} {row['æˆ¶æ•¸']:<8,} {row['å·²å”®æˆ¶æ•¸']:<8,} "
                    f"{row['æœˆå‡å»åŒ–ç‡']:<10.2f}%")
            
            # å­£åº¦è¡Œæ”¿å€æ’åè¶¨å‹¢ï¼ˆå¦‚æœæœ‰è³‡æ–™ï¼‰
            if analysis['quarterly_district_ranking'] is not None and not analysis['quarterly_district_ranking'].empty:
                print(f"\nğŸ“ˆ {city} è¡Œæ”¿å€å­£åº¦å»åŒ–ç‡è¶¨å‹¢")
                quarterly_data = analysis['quarterly_district_ranking']
                
                # é¡¯ç¤ºæœ€è¿‘å¹¾å­£çš„è³‡æ–™
                quarters = [col for col in quarterly_data.columns if not col.endswith('_æ’å')]
                quarters = sorted(quarters)[-4:]  # æœ€è¿‘4å­£
                
                print(f"{'è¡Œæ”¿å€':<12}", end="")
                for quarter in quarters:
                    print(f"{quarter:<12}", end="")
                print()
                print("-" * (12 + 12 * len(quarters)))
                
                for district in quarterly_data.index:
                    print(f"{district:<12}", end="")
                    for quarter in quarters:
                        rate = quarterly_data.loc[district, quarter]
                        if pd.notna(rate):
                            print(f"{rate:<12.1f}%", end="")
                        else:
                            print(f"{'--':<12}", end="")
                    print()
            
            # å„è¡Œæ”¿å€ç¤¾å€æ’å
            print(f"\nğŸ¯ {city} å„è¡Œæ”¿å€ç¤¾å€å»åŒ–è¡¨ç¾")
            community_ranking = analysis['district_community_ranking']
            
            for district, data in community_ranking.items():
                print(f"\nğŸ“ {district} (å…±{data['total_communities']}å€‹ç¤¾å€)")
                
                # é«˜è¡¨ç¾ç¤¾å€
                if len(data['high_performing']) > 0:
                    print(f"   ğŸ”¥ å»åŒ–è¡¨ç¾å„ªç•°ç¤¾å€:")
                    for _, community in data['high_performing'].head(5).iterrows():
                        print(f"      [{community['ç·¨è™Ÿ']}] {community['ç¤¾å€åç¨±']}: "
                            f"{community['å»åŒ–ç‡']:.1f}% (æœˆå‡{community['æœˆå‡å»åŒ–ç‡']:.2f}%, "
                            f"{community['å·²å”®æˆ¶æ•¸']}/{community['æˆ¶æ•¸']}æˆ¶)")
                
                # ä½è¡¨ç¾ç¤¾å€
                if len(data['low_performing']) > 0:
                    print(f"   âš ï¸ éœ€è¦é—œæ³¨ç¤¾å€:")
                    for _, community in data['low_performing'].head(5).iterrows():
                        print(f"      [{community['ç·¨è™Ÿ']}] {community['ç¤¾å€åç¨±']}: "
                            f"{community['å»åŒ–ç‡']:.1f}% (æœˆå‡{community['æœˆå‡å»åŒ–ç‡']:.2f}%, "
                            f"{community['å·²å”®æˆ¶æ•¸']}/{community['æˆ¶æ•¸']}æˆ¶, "
                            f"éŠ·å”®{community['éŠ·å”®å¤©æ•¸']}å¤©)")
            
            # è©²ç¸£å¸‚çš„å¸‚å ´å»ºè­°
            print(f"\nğŸ’¡ {city} å¸‚å ´åˆ†æå»ºè­°")
            
            # æ‰¾å‡ºè¡¨ç¾æœ€å¥½å’Œæœ€å·®çš„è¡Œæ”¿å€
            best_district = district_analysis.iloc[0]['è¡Œæ”¿å€']
            worst_district = district_analysis.iloc[-1]['è¡Œæ”¿å€']
            best_rate = district_analysis.iloc[0]['æ•´é«”å»åŒ–ç‡']
            worst_rate = district_analysis.iloc[-1]['æ•´é«”å»åŒ–ç‡']
            
            print(f"ğŸŒŸ è¡¨ç¾æœ€ä½³è¡Œæ”¿å€: {best_district} ({best_rate:.1f}%)")
            print(f"âš¡ éœ€è¦åŠ å¼·è¡Œæ”¿å€: {worst_district} ({worst_rate:.1f}%)")
            
            # æ ¹æ“šæ•´é«”è¡¨ç¾çµ¦å»ºè­°
            overall_rate = stats['overall_absorption_rate']
            if overall_rate > 70:
                print(f"âœ… {city}å¸‚å ´è¡¨ç¾å„ªç•°ï¼Œå»ºè­°ï¼š")
                print(f"   â€¢ å¯è€ƒæ…®åœ¨è¡¨ç¾å„ªç•°çš„è¡Œæ”¿å€å¢åŠ æ¨æ¡ˆ")
                print(f"   â€¢ é—œæ³¨é«˜å»åŒ–ç¤¾å€çš„æˆåŠŸç¶“é©—ä¸¦è¤‡è£½")
            elif overall_rate > 50:
                print(f"ğŸ”” {city}å¸‚å ´è¡¨ç¾ç©©å¥ï¼Œå»ºè­°ï¼š")
                print(f"   â€¢ åŠ å¼·å»åŒ–ç·©æ…¢ç¤¾å€çš„éŠ·å”®ç­–ç•¥")
                print(f"   â€¢ åƒè€ƒè¡¨ç¾å„ªç•°å€åŸŸçš„éŠ·å”®æ¨¡å¼")
            else:
                print(f"âš ï¸ {city}å¸‚å ´éœ€è¦é‡é»é—œæ³¨ï¼Œå»ºè­°ï¼š")
                print(f"   â€¢ é‡æ–°è©•ä¼°å®šåƒ¹ç­–ç•¥å’Œç”¢å“å®šä½")
                print(f"   â€¢ è€ƒæ…®èª¿æ•´éŠ·å”®é€šè·¯æˆ–è¡ŒéŠ·ç­–ç•¥")
                print(f"   â€¢ å¯†åˆ‡ç›£æ§å¸‚å ´è®ŠåŒ–å’Œç«¶çˆ­å‹•æ…‹")

    def create_city_visualizations(self, city_name):
        """ç‚ºç‰¹å®šç¸£å¸‚å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨"""
        if not hasattr(self, 'city_detailed_analysis') or city_name not in self.city_detailed_analysis:
            print(f"è«‹å…ˆåŸ·è¡Œ {city_name} çš„è©³ç´°åˆ†æ")
            return
        
        analysis = self.city_detailed_analysis[city_name]
        district_analysis = analysis['district_analysis']
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle(f'{city_name} å¸‚å ´åˆ†æè¦–è¦ºåŒ–', fontsize=16, fontweight='bold')
            
            # 1. è¡Œæ”¿å€å»åŒ–ç‡æ’å
            axes[0,0].barh(district_analysis['è¡Œæ”¿å€'], district_analysis['æ•´é«”å»åŒ–ç‡'], 
                        color='skyblue')
            axes[0,0].set_title(f'{city_name} è¡Œæ”¿å€å»åŒ–ç‡æ’å')
            axes[0,0].set_xlabel('æ•´é«”å»åŒ–ç‡ (%)')
            
            # æ·»åŠ æ•¸å€¼æ¨™ç±¤
            for i, v in enumerate(district_analysis['æ•´é«”å»åŒ–ç‡']):
                axes[0,0].text(v + 1, i, f'{v:.1f}%', va='center')
            
            # 2. è¡Œæ”¿å€ç¤¾å€æ•¸é‡åˆ†å¸ƒ
            axes[0,1].pie(district_analysis['ç¤¾å€æ•¸é‡'], labels=district_analysis['è¡Œæ”¿å€'], 
                        autopct='%1.1f%%', startangle=90)
            axes[0,1].set_title(f'{city_name} å„è¡Œæ”¿å€ç¤¾å€æ•¸é‡åˆ†å¸ƒ')
            
            # 3. è¡Œæ”¿å€æˆ¶æ•¸vså»åŒ–ç‡æ•£é»åœ–
            scatter = axes[1,0].scatter(district_analysis['æˆ¶æ•¸'], district_analysis['æ•´é«”å»åŒ–ç‡'], 
                                    s=district_analysis['ç¤¾å€æ•¸é‡']*20, alpha=0.6, 
                                    c=district_analysis['æœˆå‡å»åŒ–ç‡'], cmap='viridis')
            axes[1,0].set_title(f'{city_name} è¡Œæ”¿å€æˆ¶æ•¸ vs å»åŒ–ç‡')
            axes[1,0].set_xlabel('ç¸½æˆ¶æ•¸')
            axes[1,0].set_ylabel('æ•´é«”å»åŒ–ç‡ (%)')
            
            # æ·»åŠ è¡Œæ”¿å€æ¨™ç±¤
            for i, row in district_analysis.iterrows():
                axes[1,0].annotate(row['è¡Œæ”¿å€'], (row['æˆ¶æ•¸'], row['æ•´é«”å»åŒ–ç‡']), 
                                xytext=(5, 5), textcoords='offset points', fontsize=8)
            
            try:
                plt.colorbar(scatter, ax=axes[1,0], label='æœˆå‡å»åŒ–ç‡ (%)')
            except:
                pass
            
            # 4. å­£åº¦è¶¨å‹¢åœ–ï¼ˆå¦‚æœæœ‰è³‡æ–™ï¼‰
            if analysis['quarterly_district_ranking'] is not None and not analysis['quarterly_district_ranking'].empty:
                quarterly_data = analysis['quarterly_district_ranking']
                quarters = [col for col in quarterly_data.columns if not col.endswith('_æ’å')]
                quarters = sorted(quarters)
                
                for district in quarterly_data.index[:5]:  # åªé¡¯ç¤ºå‰5å€‹è¡Œæ”¿å€
                    values = [quarterly_data.loc[district, q] if pd.notna(quarterly_data.loc[district, q]) else 0 
                            for q in quarters]
                    axes[1,1].plot(quarters, values, marker='o', label=district, linewidth=2)
                
                axes[1,1].set_title(f'{city_name} è¡Œæ”¿å€å­£åº¦å»åŒ–ç‡è¶¨å‹¢')
                axes[1,1].set_xlabel('å­£åº¦')
                axes[1,1].set_ylabel('ç´¯ç©å»åŒ–ç‡ (%)')
                axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                axes[1,1].tick_params(axis='x', rotation=45)
            else:
                axes[1,1].text(0.5, 0.5, 'ç„¡å­£åº¦è³‡æ–™', ha='center', va='center', 
                            transform=axes[1,1].transAxes, fontsize=14)
                axes[1,1].set_title(f'{city_name} å­£åº¦è¶¨å‹¢ï¼ˆç„¡è³‡æ–™ï¼‰')
            
            plt.tight_layout()
            plt.show()
            
        except Exception as e:
            print(f"âš ï¸ {city_name} è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå¤±æ•—: {str(e)}")

    def export_city_detailed_results(self, filename="city_detailed_analysis", format_type="csv"):
        """åŒ¯å‡ºè©³ç´°ç¸£å¸‚åˆ†æçµæœ"""
        if not hasattr(self, 'city_detailed_analysis'):
            print("è«‹å…ˆåŸ·è¡Œè©³ç´°ç¸£å¸‚åˆ†æ")
            return
        
        if format_type.lower() == "excel":
            try:
                filename_excel = f"{filename}.xlsx"
                with pd.ExcelWriter(filename_excel, engine='openpyxl') as writer:
                    
                    # åŒ¯å‡ºæ¯å€‹ç¸£å¸‚çš„è¡Œæ”¿å€åˆ†æ
                    for city, analysis in self.city_detailed_analysis.items():
                        # è¡Œæ”¿å€åˆ†æ
                        district_df = analysis['district_analysis'].copy()
                        district_df['ç¸£å¸‚'] = city
                        district_df = district_df[['ç¸£å¸‚'] + [col for col in district_df.columns if col != 'ç¸£å¸‚']]
                        district_df.to_excel(writer, sheet_name=f'{city}_è¡Œæ”¿å€åˆ†æ', index=False)
                        
                        # å­£åº¦è¶¨å‹¢ï¼ˆå¦‚æœæœ‰ï¼‰
                        if analysis['quarterly_district_ranking'] is not None:
                            quarterly_df = analysis['quarterly_district_ranking'].copy()
                            quarterly_df.index.name = 'è¡Œæ”¿å€'
                            quarterly_df.to_excel(writer, sheet_name=f'{city}_å­£åº¦è¶¨å‹¢')
                        
                        # ç¤¾å€æ’ååŒ¯ç¸½
                        community_summary = []
                        for district, data in analysis['district_community_ranking'].items():
                            # é«˜è¡¨ç¾ç¤¾å€
                            for _, community in data['high_performing'].iterrows():
                                community_summary.append({
                                    'ç¸£å¸‚': city,
                                    'è¡Œæ”¿å€': district,
                                    'ç·¨è™Ÿ': community['ç·¨è™Ÿ'],
                                    'ç¤¾å€åç¨±': community['ç¤¾å€åç¨±'],
                                    'å»åŒ–ç‡': community['å»åŒ–ç‡'],
                                    'æœˆå‡å»åŒ–ç‡': community['æœˆå‡å»åŒ–ç‡'],
                                    'å·²å”®æˆ¶æ•¸': community['å·²å”®æˆ¶æ•¸'],
                                    'ç¸½æˆ¶æ•¸': community['æˆ¶æ•¸'],
                                    'è¡¨ç¾é¡åˆ¥': 'å„ªç•°'
                                })
                            
                            # ä½è¡¨ç¾ç¤¾å€
                            for _, community in data['low_performing'].iterrows():
                                community_summary.append({
                                    'ç¸£å¸‚': city,
                                    'è¡Œæ”¿å€': district,
                                    'ç·¨è™Ÿ': community['ç·¨è™Ÿ'],
                                    'ç¤¾å€åç¨±': community['ç¤¾å€åç¨±'],
                                    'å»åŒ–ç‡': community['å»åŒ–ç‡'],
                                    'æœˆå‡å»åŒ–ç‡': community['æœˆå‡å»åŒ–ç‡'],
                                    'å·²å”®æˆ¶æ•¸': community['å·²å”®æˆ¶æ•¸'],
                                    'ç¸½æˆ¶æ•¸': community['æˆ¶æ•¸'],
                                    'è¡¨ç¾é¡åˆ¥': 'éœ€é—œæ³¨'
                                })
                        
                        if community_summary:
                            community_df = pd.DataFrame(community_summary)
                            community_df.to_excel(writer, sheet_name=f'{city}_ç¤¾å€æ’å', index=False)
                
                print(f"è©³ç´°ç¸£å¸‚åˆ†æçµæœå·²åŒ¯å‡ºè‡³: {filename_excel}")
                
            except ImportError:
                print("âŒ ç¼ºå°‘ openpyxl å¥—ä»¶ï¼Œç„¡æ³•åŒ¯å‡º Excel æ ¼å¼")
                print("è«‹åŸ·è¡Œ: pip install openpyxl")
                print("æ”¹ç‚ºåŒ¯å‡º CSV æ ¼å¼...")
                format_type = "csv"
        
        if format_type.lower() == "csv":
            # åŒ¯å‡ºç‚ºå¤šå€‹ CSV æª”æ¡ˆ
            files_exported = []
            
            for city, analysis in self.city_detailed_analysis.items():
                # è¡Œæ”¿å€åˆ†æ
                district_df = analysis['district_analysis'].copy()
                district_df['ç¸£å¸‚'] = city
                district_filename = f"{filename}_{city}_è¡Œæ”¿å€åˆ†æ.csv"
                district_df.to_csv(district_filename, index=False, encoding='utf-8-sig')
                files_exported.append(district_filename)
                
                # å­£åº¦è¶¨å‹¢
                if analysis['quarterly_district_ranking'] is not None:
                    quarterly_filename = f"{filename}_{city}_å­£åº¦è¶¨å‹¢.csv"
                    analysis['quarterly_district_ranking'].to_csv(quarterly_filename, encoding='utf-8-sig')
                    files_exported.append(quarterly_filename)
                
                # ç¤¾å€æ’å
                community_summary = []
                for district, data in analysis['district_community_ranking'].items():
                    for _, community in data['high_performing'].iterrows():
                        community_summary.append({
                            'ç¸£å¸‚': city, 'è¡Œæ”¿å€': district, 'ç·¨è™Ÿ': community['ç·¨è™Ÿ'],
                            'ç¤¾å€åç¨±': community['ç¤¾å€åç¨±'], 'å»åŒ–ç‡': community['å»åŒ–ç‡'],
                            'æœˆå‡å»åŒ–ç‡': community['æœˆå‡å»åŒ–ç‡'], 'å·²å”®æˆ¶æ•¸': community['å·²å”®æˆ¶æ•¸'],
                            'ç¸½æˆ¶æ•¸': community['æˆ¶æ•¸'], 'è¡¨ç¾é¡åˆ¥': 'å„ªç•°'
                        })
                    
                    for _, community in data['low_performing'].iterrows():
                        community_summary.append({
                            'ç¸£å¸‚': city, 'è¡Œæ”¿å€': district, 'ç·¨è™Ÿ': community['ç·¨è™Ÿ'],
                            'ç¤¾å€åç¨±': community['ç¤¾å€åç¨±'], 'å»åŒ–ç‡': community['å»åŒ–ç‡'],
                            'æœˆå‡å»åŒ–ç‡': community['æœˆå‡å»åŒ–ç‡'], 'å·²å”®æˆ¶æ•¸': community['å·²å”®æˆ¶æ•¸'],
                            'ç¸½æˆ¶æ•¸': community['æˆ¶æ•¸'], 'è¡¨ç¾é¡åˆ¥': 'éœ€é—œæ³¨'
                        })
                
                if community_summary:
                    community_df = pd.DataFrame(community_summary)
                    community_filename = f"{filename}_{city}_ç¤¾å€æ’å.csv"
                    community_df.to_csv(community_filename, index=False, encoding='utf-8-sig')
                    files_exported.append(community_filename)
            
            print(f"è©³ç´°ç¸£å¸‚åˆ†æçµæœå·²åŒ¯å‡ºç‚º CSV æ ¼å¼:")
            for file in files_exported:
                print(f"  - {file}")

    def analyze_single_city(self, city_name):
        """åˆ†æå–®ä¸€ç¸£å¸‚çš„è©³ç´°å ±å‘Š"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡ŒåŸºæœ¬å»åŒ–ç‡è¨ˆç®—")
            return
        
        # æª¢æŸ¥ç¸£å¸‚æ˜¯å¦å­˜åœ¨
        available_cities = self.analysis_result['ç¸£å¸‚'].unique()
        if city_name not in available_cities:
            print(f"âŒ æ‰¾ä¸åˆ°ç¸£å¸‚ '{city_name}'")
            print(f"å¯ç”¨çš„ç¸£å¸‚: {', '.join(available_cities)}")
            return
        
        print(f"ğŸ¯ é–‹å§‹åˆ†æ {city_name}...")
        
        # åŸ·è¡Œå­£åº¦åˆ†æï¼ˆå¦‚æœé‚„æ²’åšéï¼‰
        if not hasattr(self, 'quarterly_analysis'):
            self.analyze_quarterly_trends()
        
        # åŸ·è¡Œè©²ç¸£å¸‚çš„è©³ç´°åˆ†æ
        self.analyze_city_detailed(city_name)
        
        # ç”Ÿæˆè©³ç´°å ±å‘Š
        self.generate_city_detailed_report(city_name)
        
        # å‰µå»ºè¦–è¦ºåŒ–
        try:
            self.create_city_visualizations(city_name)
        except Exception as e:
            print(f"âš ï¸ {city_name} è¦–è¦ºåŒ–å¤±æ•—: {str(e)}")
        
        print(f"âœ… {city_name} åˆ†æå®Œæˆï¼")
        return self.city_detailed_analysis.get(city_name)

    
    def check_data_matching(self):
        """æª¢æŸ¥å…©å€‹æª”æ¡ˆçš„ç·¨è™Ÿæ¯”å°æƒ…æ³"""
        print("\n" + "="*50)
        print("è³‡æ–™æ¯”å°æª¢æŸ¥å ±å‘Š")
        print("="*50)
        
        if 'å‚™æŸ¥ç·¨è™Ÿ' not in self.transaction_data.columns:
            print("âŒ äº¤æ˜“è³‡æ–™ä¸­æ‰¾ä¸åˆ° 'å‚™æŸ¥ç·¨è™Ÿ' æ¬„ä½")
            return
        
        if 'ç·¨è™Ÿ' not in self.community_data.columns:
            print("âŒ ç¤¾å€è³‡æ–™ä¸­æ‰¾ä¸åˆ° 'ç·¨è™Ÿ' æ¬„ä½")
            return
        
        # åˆ†æç·¨è™Ÿæ¯”å°æƒ…æ³
        transaction_with_id = self.transaction_data.dropna(subset=['å‚™æŸ¥ç·¨è™Ÿ'])
        community_with_id = self.community_data.dropna(subset=['ç·¨è™Ÿ'])
        
        transaction_ids = set(transaction_with_id['å‚™æŸ¥ç·¨è™Ÿ'].astype(str))
        community_ids = set(community_with_id['ç·¨è™Ÿ'].astype(str))
        matched_ids = transaction_ids.intersection(community_ids)
        
        # åªåœ¨äº¤æ˜“è³‡æ–™ä¸­æœ‰çš„ç·¨è™Ÿ
        only_in_transaction = transaction_ids - community_ids
        # åªåœ¨ç¤¾å€è³‡æ–™ä¸­æœ‰çš„ç·¨è™Ÿ
        only_in_community = community_ids - transaction_ids
        
        print(f"ğŸ“Š ç·¨è™Ÿæ¯”å°çµ±è¨ˆï¼š")
        print(f"äº¤æ˜“è³‡æ–™ç·¨è™Ÿç¸½æ•¸: {len(transaction_ids)}")
        print(f"ç¤¾å€è³‡æ–™ç·¨è™Ÿç¸½æ•¸: {len(community_ids)}")
        print(f"âœ… æˆåŠŸæ¯”å°ç·¨è™Ÿæ•¸: {len(matched_ids)}")
        print(f"âš ï¸ åƒ…å­˜åœ¨æ–¼äº¤æ˜“è³‡æ–™: {len(only_in_transaction)}")
        print(f"âš ï¸ åƒ…å­˜åœ¨æ–¼ç¤¾å€è³‡æ–™: {len(only_in_community)}")
        print(f"ğŸ“ˆ æ¯”å°æˆåŠŸç‡: {len(matched_ids)/max(len(transaction_ids), len(community_ids))*100:.1f}%")
        
        if len(matched_ids) == 0:
            print("\nâŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„ç·¨è™Ÿ!")
            print("å»ºè­°æª¢æŸ¥ï¼š")
            print("1. ç·¨è™Ÿæ ¼å¼æ˜¯å¦ä¸€è‡´")
            print("2. æ˜¯å¦æœ‰å‰å¾Œç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦")
            print("3. æ•¸æ“šé¡å‹æ˜¯å¦ç›¸åŒ")
            
            # é¡¯ç¤ºç¯„ä¾‹ç·¨è™Ÿä¾›æª¢æŸ¥
            print(f"\nç¯„ä¾‹äº¤æ˜“è³‡æ–™ç·¨è™Ÿ: {list(transaction_ids)[:5]}")
            print(f"ç¯„ä¾‹ç¤¾å€è³‡æ–™ç·¨è™Ÿ: {list(community_ids)[:5]}")
        
    def analyze_district_performance(self):
        """åˆ†æè¡Œæ”¿å€å»åŒ–è¡¨ç¾"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return None
        
        print("æ­£åœ¨é€²è¡Œè¡Œæ”¿å€åˆ†æ...")
        
        # è¡Œæ”¿å€å±¤ç´šçµ±è¨ˆ
        district_stats = self.analysis_result.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€']).agg({
            'æˆ¶æ•¸': 'sum',
            'å·²å”®æˆ¶æ•¸': 'sum',
            'å»åŒ–ç‡': 'mean',
            'æœˆå‡å»åŒ–ç‡': 'mean',
            'éŠ·å”®å¤©æ•¸': 'mean'
        }).reset_index()
        
        # è¨ˆç®—è¡Œæ”¿å€æ•´é«”å»åŒ–ç‡
        district_stats['æ•´é«”å»åŒ–ç‡'] = (district_stats['å·²å”®æˆ¶æ•¸'] / district_stats['æˆ¶æ•¸']) * 100
        district_stats['æ•´é«”å»åŒ–ç‡'] = district_stats['æ•´é«”å»åŒ–ç‡'].round(2)
        
        # è¨ˆç®—ç¤¾å€æ•¸é‡
        district_community_count = self.analysis_result.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€']).size().reset_index(name='ç¤¾å€æ•¸é‡')
        district_stats = pd.merge(district_stats, district_community_count, on=['ç¸£å¸‚', 'è¡Œæ”¿å€'])
        
        # è¨ˆç®—è¡Œæ”¿å€çš„å»åŒ–è¡¨ç¾åˆ†ç´š
        def categorize_district_performance(rate):
            if rate >= 80:
                return 'å„ªç•°'
            elif rate >= 60:
                return 'è‰¯å¥½'
            elif rate >= 40:
                return 'æ™®é€š'
            elif rate >= 20:
                return 'å¾…æ”¹å–„'
            else:
                return 'å›°é›£'
        
        district_stats['è¡¨ç¾ç­‰ç´š'] = district_stats['æ•´é«”å»åŒ–ç‡'].apply(categorize_district_performance)
        
        # æ’åº
        district_stats = district_stats.sort_values('æ•´é«”å»åŒ–ç‡', ascending=False)
        
        self.district_analysis = district_stats
        print(f"âœ… è¡Œæ”¿å€åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(district_stats)} å€‹è¡Œæ”¿å€")
        return district_stats
    
    def analyze_city_performance(self):
        """åˆ†æç¸£å¸‚å»åŒ–è¡¨ç¾"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return None
        
        print("æ­£åœ¨é€²è¡Œç¸£å¸‚åˆ†æ...")
        
        # ç¸£å¸‚å±¤ç´šçµ±è¨ˆ
        city_stats = self.analysis_result.groupby('ç¸£å¸‚').agg({
            'æˆ¶æ•¸': 'sum',
            'å·²å”®æˆ¶æ•¸': 'sum',
            'å»åŒ–ç‡': 'mean',
            'æœˆå‡å»åŒ–ç‡': 'mean',
            'éŠ·å”®å¤©æ•¸': 'mean'
        }).reset_index()
        
        # è¨ˆç®—ç¸£å¸‚æ•´é«”å»åŒ–ç‡
        city_stats['æ•´é«”å»åŒ–ç‡'] = (city_stats['å·²å”®æˆ¶æ•¸'] / city_stats['æˆ¶æ•¸']) * 100
        city_stats['æ•´é«”å»åŒ–ç‡'] = city_stats['æ•´é«”å»åŒ–ç‡'].round(2)
        
        # è¨ˆç®—è¡Œæ”¿å€æ•¸é‡å’Œç¤¾å€æ•¸é‡
        city_district_count = self.analysis_result.groupby('ç¸£å¸‚')['è¡Œæ”¿å€'].nunique().reset_index()
        city_district_count.columns = ['ç¸£å¸‚', 'è¡Œæ”¿å€æ•¸é‡']
        
        city_community_count = self.analysis_result.groupby('ç¸£å¸‚').size().reset_index(name='ç¤¾å€æ•¸é‡')
        
        city_stats = pd.merge(city_stats, city_district_count, on='ç¸£å¸‚')
        city_stats = pd.merge(city_stats, city_community_count, on='ç¸£å¸‚')
        
        # è¨ˆç®—ç¸£å¸‚çš„å»åŒ–è¡¨ç¾åˆ†ç´š
        def categorize_city_performance(rate):
            if rate >= 70:
                return 'ç†±é–€'
            elif rate >= 50:
                return 'ç©©å¥'
            elif rate >= 30:
                return 'å¹³ç©©'
            else:
                return 'å†·æ·¡'
        
        city_stats['å¸‚å ´ç†±åº¦'] = city_stats['æ•´é«”å»åŒ–ç‡'].apply(categorize_city_performance)
        
        # æ’åº
        city_stats = city_stats.sort_values('æ•´é«”å»åŒ–ç‡', ascending=False)
        
        self.city_analysis = city_stats
        print(f"âœ… ç¸£å¸‚åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(city_stats)} å€‹ç¸£å¸‚")
        return city_stats
    
    def convert_taiwan_date(self, date_val):
        """å°‡æ°‘åœ‹å¹´æ—¥æœŸè½‰æ›ç‚ºè¥¿å…ƒå¹´æ—¥æœŸ"""
        if pd.isna(date_val) or date_val == 0:
            return None
        
        try:
            date_str = str(int(date_val))
            if len(date_str) == 7:  # 1120101 æ ¼å¼
                year = int(date_str[:3]) + 1911  # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´
                month = int(date_str[3:5])
                day = int(date_str[5:7])
                return datetime(year, month, day)
            elif len(date_str) == 6:  # 112101 æ ¼å¼
                year = int(date_str[:3]) + 1911
                month = int(date_str[3:5])
                day = int(date_str[5:6]) if len(date_str[5:]) == 1 else int(date_str[5:7])
                return datetime(year, month, day)
        except:
            return None
        
        return None
    
    def convert_taiwan_yearmonth(self, yearmonth_val):
        """å°‡æ°‘åœ‹å¹´æœˆè½‰æ›ç‚ºè¥¿å…ƒå¹´æœˆ"""
        if pd.isna(yearmonth_val):
            return None
        
        try:
            yearmonth_str = str(int(yearmonth_val))
            if len(yearmonth_str) >= 5:
                year = int(yearmonth_str[:3]) + 1911
                month = int(yearmonth_str[3:5])
                return datetime(year, month, 1)
        except:
            return None
        
        return None
    
    def preprocess_data(self):
        """æ•¸æ“šé è™•ç†"""
        print("æ­£åœ¨é€²è¡Œæ•¸æ“šé è™•ç†...")
        
        # è§£ææ—¥æœŸæ¬„ä½
        self.parse_date_columns()
        
        # è™•ç†äº¤æ˜“è³‡æ–™
        self.transaction_data = self.transaction_data.dropna(subset=['ç¤¾å€åç¨±', 'ç¸£å¸‚', 'è¡Œæ”¿å€'])
        
        # è™•ç†ç¤¾å€è³‡æ–™
        self.community_data = self.community_data.dropna(subset=['ç¤¾å€åç¨±', 'æˆ¶æ•¸'])
        self.community_data['æˆ¶æ•¸'] = pd.to_numeric(self.community_data['æˆ¶æ•¸'], errors='coerce')
        self.community_data = self.community_data.dropna(subset=['æˆ¶æ•¸'])
        
        # è¨ˆç®—éŠ·å”®æœŸé–“
        self.calculate_sales_period()
        
        # æª¢æŸ¥ç·¨è™Ÿæ¯”å°æƒ…æ³
        matched_count = self.check_data_matching()
        if matched_count == 0:
            print("âŒ è³‡æ–™é è™•ç†ä¸­æ­¢ï¼šç„¡æ³•æ‰¾åˆ°åŒ¹é…çš„ç·¨è™Ÿ")
            return None
        
        print("âœ… æ•¸æ“šé è™•ç†å®Œæˆ")
        return self
    
    def calculate_sales_period(self):
        """è¨ˆç®—éŠ·å”®æœŸé–“ç›¸é—œæŒ‡æ¨™"""
        # ç¢ºå®šéŠ·å”®èµ·å§‹æ—¥æœŸ (å„ªå…ˆé †åºï¼šéŠ·å”®èµ·å§‹æ™‚é–“ > è‡ªå”®èµ·å§‹æ™‚é–“ > ä»£éŠ·èµ·å§‹æ™‚é–“)
        self.community_data['éŠ·å”®é–‹å§‹æ—¥æœŸ'] = (
            self.community_data['éŠ·å”®èµ·å§‹æ™‚é–“_date'].fillna(
                self.community_data['è‡ªå”®èµ·å§‹æ™‚é–“_date'].fillna(
                    self.community_data['ä»£éŠ·èµ·å§‹æ™‚é–“_date']
                )
            )
        )
        
        # è¨ˆç®—æˆªè‡³åˆ†ææ—¥æœŸçš„éŠ·å”®å¤©æ•¸
        self.community_data['éŠ·å”®å¤©æ•¸'] = (
            self.current_date - self.community_data['éŠ·å”®é–‹å§‹æ—¥æœŸ']
        ).dt.days
        
        # è™•ç†è² å€¼æˆ–ç•°å¸¸å€¼
        self.community_data['éŠ·å”®å¤©æ•¸'] = self.community_data['éŠ·å”®å¤©æ•¸'].apply(
            lambda x: max(0, x) if pd.notna(x) else 0
        )
        
        # éŠ·å”®æœŸé–“åˆ†é¡
        self.community_data['éŠ·å”®éšæ®µ'] = pd.cut(
            self.community_data['éŠ·å”®å¤©æ•¸'],
            bins=[0, 90, 180, 365, 730, float('inf')],
            labels=['æ–°æ¨æ¡ˆ(<3å€‹æœˆ)', 'åˆæœŸéŠ·å”®(3-6å€‹æœˆ)', 'ç©©å®šéŠ·å”®(6-12å€‹æœˆ)', 
                   'é•·æœŸéŠ·å”®(1-2å¹´)', 'é•·æœŸéŠ·å”®(>2å¹´)'],
            include_lowest=True
        )
    
    def calculate_time_adjusted_absorption_rate(self):
        """è¨ˆç®—è€ƒæ…®æ™‚é–“å› ç´ çš„å»åŒ–ç‡"""
        print("æ­£åœ¨è¨ˆç®—æ™‚é–“èª¿æ•´å¾Œçš„å»åŒ–ç‡...")
        
        # é¦–å…ˆç¢ºä¿ç·¨è™Ÿæ¬„ä½å­˜åœ¨
        if 'å‚™æŸ¥ç·¨è™Ÿ' not in self.transaction_data.columns:
            print("âŒ äº¤æ˜“è³‡æ–™ä¸­ç¼ºå°‘ 'å‚™æŸ¥ç·¨è™Ÿ' æ¬„ä½")
            return self
        
        if 'ç·¨è™Ÿ' not in self.community_data.columns:
            print("âŒ ç¤¾å€è³‡æ–™ä¸­ç¼ºå°‘ 'ç·¨è™Ÿ' æ¬„ä½")
            return self
        
        # å…ˆç”¨ç·¨è™Ÿæ¯”å°ï¼Œç¢ºä¿åªåˆ†ææœ‰å°æ‡‰ç·¨è™Ÿçš„ç¤¾å€
        print("æ­£åœ¨é€²è¡Œç·¨è™Ÿæ¯”å°...")
        
        # æ¸…ç†ç·¨è™Ÿè³‡æ–™ï¼ˆç§»é™¤ç©ºå€¼ï¼‰
        transaction_with_id = self.transaction_data.dropna(subset=['å‚™æŸ¥ç·¨è™Ÿ'])
        community_with_id = self.community_data.dropna(subset=['ç·¨è™Ÿ'])
        
        # å–å¾—æœ‰å°æ‡‰ç·¨è™Ÿçš„ç¤¾å€æ¸…å–®
        transaction_ids = set(transaction_with_id['å‚™æŸ¥ç·¨è™Ÿ'].astype(str))
        community_ids = set(community_with_id['ç·¨è™Ÿ'].astype(str))
        matched_ids = transaction_ids.intersection(community_ids)
        
        print(f"äº¤æ˜“è³‡æ–™ä¸­çš„å‚™æŸ¥ç·¨è™Ÿæ•¸é‡: {len(transaction_ids)}")
        print(f"ç¤¾å€è³‡æ–™ä¸­çš„ç·¨è™Ÿæ•¸é‡: {len(community_ids)}")
        print(f"æˆåŠŸæ¯”å°çš„ç·¨è™Ÿæ•¸é‡: {len(matched_ids)}")
        
        if len(matched_ids) == 0:
            print("âŒ æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„ç·¨è™Ÿï¼Œè«‹æª¢æŸ¥ç·¨è™Ÿæ ¼å¼æ˜¯å¦ä¸€è‡´")
            return self
        
        # ç¯©é¸å‡ºæœ‰åŒ¹é…ç·¨è™Ÿçš„è³‡æ–™
        filtered_transaction = transaction_with_id[
            transaction_with_id['å‚™æŸ¥ç·¨è™Ÿ'].astype(str).isin(matched_ids)
        ].copy()
        
        filtered_community = community_with_id[
            community_with_id['ç·¨è™Ÿ'].astype(str).isin(matched_ids)
        ].copy()
        
        # è¨ˆç®—æ¯å€‹ç·¨è™Ÿçš„éŠ·å”®æˆ¶æ•¸
        sold_units = filtered_transaction.groupby('å‚™æŸ¥ç·¨è™Ÿ').size().reset_index(name='å·²å”®æˆ¶æ•¸')
        sold_units['å‚™æŸ¥ç·¨è™Ÿ'] = sold_units['å‚™æŸ¥ç·¨è™Ÿ'].astype(str)
        
        # æº–å‚™ç¤¾å€è³‡æ–™é€²è¡Œåˆä½µ
        community_for_merge = filtered_community.copy()
        community_for_merge['ç·¨è™Ÿ'] = community_for_merge['ç·¨è™Ÿ'].astype(str)
        
        # ä½¿ç”¨ç·¨è™Ÿé€²è¡Œç²¾ç¢ºåˆä½µ
        merged_data = pd.merge(
            community_for_merge[['ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¤¾å€åç¨±', 'æˆ¶æ•¸', 'éŠ·å”®é–‹å§‹æ—¥æœŸ', 'éŠ·å”®å¤©æ•¸', 'éŠ·å”®éšæ®µ']],
            sold_units,
            left_on='ç·¨è™Ÿ',
            right_on='å‚™æŸ¥ç·¨è™Ÿ',
            how='left'
        )
        # å¡«è£œæœªå”®å‡ºçš„ç¤¾å€
        merged_data['å·²å”®æˆ¶æ•¸'] = merged_data['å·²å”®æˆ¶æ•¸'].fillna(0)
        
        # è¨ˆç®—åŸºæœ¬å»åŒ–ç‡
        merged_data['å»åŒ–ç‡'] = (merged_data['å·²å”®æˆ¶æ•¸'] / merged_data['æˆ¶æ•¸']) * 100
        merged_data['å»åŒ–ç‡'] = merged_data['å»åŒ–ç‡'].round(2)
        
        # è¨ˆç®—å»åŒ–é€Ÿåº¦ (æ¯æœˆå»åŒ–ç‡)
        merged_data['éŠ·å”®æœˆæ•¸'] = merged_data['éŠ·å”®å¤©æ•¸'] / 30.44  # å¹³å‡æ¯æœˆå¤©æ•¸
        merged_data['éŠ·å”®æœˆæ•¸'] = merged_data['éŠ·å”®æœˆæ•¸'].apply(lambda x: max(0.5, x))  # æœ€å°‘0.5å€‹æœˆ
        merged_data['æœˆå‡å»åŒ–ç‡'] = merged_data['å»åŒ–ç‡'] / merged_data['éŠ·å”®æœˆæ•¸']
        merged_data['æœˆå‡å»åŒ–ç‡'] = merged_data['æœˆå‡å»åŒ–ç‡'].round(2)
        
        # é ä¼°å®Œå…¨å»åŒ–æ‰€éœ€æ™‚é–“
        merged_data['é ä¼°å®Œå…¨å»åŒ–æœˆæ•¸'] = np.where(
            merged_data['æœˆå‡å»åŒ–ç‡'] > 0,
            100 / merged_data['æœˆå‡å»åŒ–ç‡'],
            float('inf')
        )
        
        # åˆ†é¡å»åŒ–è¡¨ç¾ (è€ƒæ…®éŠ·å”®æœŸé–“)
        def categorize_performance(row):
            if row['éŠ·å”®å¤©æ•¸'] < 90:  # æ–°æ¨æ¡ˆ
                if row['å»åŒ–ç‡'] > 20:
                    return 'æ–°æ¡ˆç†±éŠ·'
                elif row['å»åŒ–ç‡'] > 10:
                    return 'æ–°æ¡ˆç©©å¥'
                else:
                    return 'æ–°æ¡ˆå¾…è§€å¯Ÿ'
            elif row['éŠ·å”®å¤©æ•¸'] < 365:  # ä¸€å¹´å…§
                if row['å»åŒ–ç‡'] > 70:
                    return 'éŠ·å”®å„ªç•°'
                elif row['å»åŒ–ç‡'] > 40:
                    return 'éŠ·å”®è‰¯å¥½'
                elif row['å»åŒ–ç‡'] > 20:
                    return 'éŠ·å”®æ™®é€š'
                else:
                    return 'éŠ·å”®ç·©æ…¢'
            else:  # è¶…éä¸€å¹´
                if row['å»åŒ–ç‡'] > 80:
                    return 'é•·æœŸç©©å¥'
                elif row['å»åŒ–ç‡'] > 50:
                    return 'æŒçºŒéŠ·å”®'
                elif row['å»åŒ–ç‡'] > 30:
                    return 'éŠ·å”®é²ç·©'
                else:
                    return 'å»åŒ–å›°é›£'
        
        merged_data['éŠ·å”®è¡¨ç¾'] = merged_data.apply(categorize_performance, axis=1)
        
        self.analysis_result = merged_data
        print(f"âœ… æ™‚é–“èª¿æ•´å»åŒ–ç‡è¨ˆç®—å®Œæˆï¼Œå…±åˆ†æ {len(merged_data)} å€‹æœ‰ç·¨è™Ÿæ¯”å°çš„ç¤¾å€")
        return self
    
    def generate_time_aware_report(self):
        """ç”Ÿæˆè€ƒæ…®æ™‚é–“å› ç´ çš„åˆ†æå ±å‘Š"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return
        
        print("\n" + "="*60)
        print("é å”®å±‹å¸‚å ´æ™‚é–“èª¿æ•´å»åŒ–ç‡åˆ†æå ±å‘Š")
        print("(åŸºæ–¼å‚™æŸ¥ç·¨è™Ÿç²¾ç¢ºæ¯”å°)")
        print("="*60)
        
        # æ•´é«”æ¦‚æ³
        total_communities = len(self.analysis_result)
        total_units = self.analysis_result['æˆ¶æ•¸'].sum()
        total_sold = self.analysis_result['å·²å”®æˆ¶æ•¸'].sum()
        overall_rate = (total_sold / total_units) * 100
        avg_monthly_rate = self.analysis_result['æœˆå‡å»åŒ–ç‡'].mean()
        
        print(f"\nğŸ“Š æ•´é«”å¸‚å ´æ¦‚æ³")
        print(f"âœ… æˆåŠŸæ¯”å°ç¤¾å€æ•¸: {total_communities:,} å€‹")
        print(f"ğŸ“‹ é€™äº›ç¤¾å€åœ¨å…©å€‹æª”æ¡ˆä¸­éƒ½æœ‰å°æ‡‰çš„å‚™æŸ¥ç·¨è™Ÿ/ç·¨è™Ÿ")
        print(f"ğŸ  ç¸½æˆ¶æ•¸: {total_units:,} æˆ¶")
        print(f"ğŸ’° å·²å”®æˆ¶æ•¸: {total_sold:,} æˆ¶") 
        print(f"ğŸ“ˆ æ•´é«”å»åŒ–ç‡: {overall_rate:.2f}%")
        print(f"âš¡ å¹³å‡æœˆå»åŒ–ç‡: {avg_monthly_rate:.2f}%")
        
        # è³‡æ–™åŒ¹é…ç‹€æ³èªªæ˜
        print(f"\nğŸ”— è³‡æ–™æ¯”å°èªªæ˜")
        print(f"æœ¬åˆ†æåƒ…åŒ…å«åœ¨ä»¥ä¸‹å…©å€‹æª”æ¡ˆä¸­éƒ½æœ‰å°æ‡‰ç·¨è™Ÿçš„ç¤¾å€ï¼š")
        print(f"  â€¢ äº¤æ˜“è³‡æ–™ (lvr_pre_sale_test.csv) - å‚™æŸ¥ç·¨è™Ÿæ¬„ä½")
        print(f"  â€¢ ç¤¾å€è³‡æ–™ (lvr_sale_data_test.csv) - ç·¨è™Ÿæ¬„ä½")
        print(f"é€™ç¢ºä¿äº†åˆ†æçš„æº–ç¢ºæ€§å’Œè³‡æ–™å®Œæ•´æ€§")
        
        # éŠ·å”®éšæ®µåˆ†æ
        print(f"\nâ° ä¸åŒéŠ·å”®éšæ®µè¡¨ç¾")
        stage_analysis = self.analysis_result.groupby('éŠ·å”®éšæ®µ').agg({
            'æˆ¶æ•¸': 'sum',
            'å·²å”®æˆ¶æ•¸': 'sum',
            'å»åŒ–ç‡': 'mean',
            'æœˆå‡å»åŒ–ç‡': 'mean'
        }).reset_index()
        stage_analysis['æ•´é«”å»åŒ–ç‡'] = (stage_analysis['å·²å”®æˆ¶æ•¸'] / stage_analysis['æˆ¶æ•¸']) * 100
        
        for _, row in stage_analysis.iterrows():
            community_count = len(self.analysis_result[self.analysis_result['éŠ·å”®éšæ®µ']==row['éŠ·å”®éšæ®µ']])
            print(f"{row['éŠ·å”®éšæ®µ']}: å»åŒ–ç‡ {row['æ•´é«”å»åŒ–ç‡']:.1f}%, "
                  f"æœˆå‡å»åŒ–ç‡ {row['æœˆå‡å»åŒ–ç‡']:.2f}%, ç¤¾å€æ•¸ {community_count} å€‹")
        
        # éŠ·å”®è¡¨ç¾åˆ†å¸ƒ
        print(f"\nğŸ¯ éŠ·å”®è¡¨ç¾åˆ†å¸ƒ")
        performance_dist = self.analysis_result['éŠ·å”®è¡¨ç¾'].value_counts()
        for performance, count in performance_dist.items():
            percentage = (count / total_communities) * 100
            print(f"{performance}: {count} å€‹ç¤¾å€ ({percentage:.1f}%)")
        
        # é«˜æ•ˆå»åŒ–ç¤¾å€ (æœˆå‡å»åŒ–ç‡é«˜)
        print(f"\nğŸš€ é«˜æ•ˆå»åŒ–ç¤¾å€ (æœˆå‡å»åŒ–ç‡ > 5%)")
        high_efficiency = self.analysis_result[self.analysis_result['æœˆå‡å»åŒ–ç‡'] > 5].sort_values('æœˆå‡å»åŒ–ç‡', ascending=False)
        if len(high_efficiency) > 0:
            for _, row in high_efficiency.head(10).iterrows():
                print(f"[{row['ç·¨è™Ÿ']}] {row['ç¸£å¸‚']}-{row['è¡Œæ”¿å€']}-{row['ç¤¾å€åç¨±']}: "
                      f"æœˆå‡ {row['æœˆå‡å»åŒ–ç‡']:.2f}%, ç´¯è¨ˆ {row['å»åŒ–ç‡']:.1f}%, "
                      f"éŠ·å”® {row['éŠ·å”®å¤©æ•¸']} å¤©")
        else:
            print("ç›®å‰ç„¡æœˆå‡å»åŒ–ç‡è¶…é5%çš„ç¤¾å€")
        
        # å»åŒ–å›°é›£ç¤¾å€ (éŠ·å”®æ™‚é–“é•·ä½†å»åŒ–ç‡ä½)
        print(f"\nâš ï¸ éœ€é—œæ³¨ç¤¾å€ (éŠ·å”®è¶…é6å€‹æœˆä¸”å»åŒ–ç‡<30%)")
        concern_communities = self.analysis_result[
            (self.analysis_result['éŠ·å”®å¤©æ•¸'] > 180) & 
            (self.analysis_result['å»åŒ–ç‡'] < 30)
        ].sort_values('éŠ·å”®å¤©æ•¸', ascending=False)
        
        if len(concern_communities) > 0:
            for _, row in concern_communities.head(10).iterrows():
                print(f"[{row['ç·¨è™Ÿ']}] {row['ç¸£å¸‚']}-{row['è¡Œæ”¿å€']}-{row['ç¤¾å€åç¨±']}: "
                      f"å»åŒ–ç‡ {row['å»åŒ–ç‡']:.1f}%, éŠ·å”® {row['éŠ·å”®å¤©æ•¸']} å¤©, "
                      f"æˆ¶æ•¸ {row['æˆ¶æ•¸']} æˆ¶")
        else:
            print("ç›®å‰ç„¡éœ€ç‰¹åˆ¥é—œæ³¨çš„ç¤¾å€")
    
    def generate_district_city_report(self):
        """ç”Ÿæˆç¸£å¸‚è¡Œæ”¿å€åˆ†æå ±å‘Š"""
        if not hasattr(self, 'district_analysis') or not hasattr(self, 'city_analysis'):
            print("è«‹å…ˆåŸ·è¡Œç¸£å¸‚å’Œè¡Œæ”¿å€åˆ†æ")
            return
        
        print("\n" + "="*60)
        print("ç¸£å¸‚èˆ‡è¡Œæ”¿å€å»åŒ–ç‡æ·±åº¦åˆ†æ")
        print("="*60)
        
        # ç¸£å¸‚è¡¨ç¾åˆ†æ
        print(f"\nğŸ™ï¸ ç¸£å¸‚å¸‚å ´è¡¨ç¾æ’å")
        print(f"{'æ’å':<4} {'ç¸£å¸‚':<8} {'æ•´é«”å»åŒ–ç‡':<10} {'ç¸½æˆ¶æ•¸':<8} {'å·²å”®æˆ¶æ•¸':<8} {'ç¤¾å€æ•¸':<6} {'è¡Œæ”¿å€æ•¸':<6} {'å¸‚å ´ç†±åº¦':<8}")
        print("-" * 70)
        
        for idx, row in self.city_analysis.head(15).iterrows():
            print(f"{idx+1:<4} {row['ç¸£å¸‚']:<8} {row['æ•´é«”å»åŒ–ç‡']:<10.1f}% "
                  f"{row['æˆ¶æ•¸']:<8,} {row['å·²å”®æˆ¶æ•¸']:<8,} {row['ç¤¾å€æ•¸é‡']:<6} "
                  f"{row['è¡Œæ”¿å€æ•¸é‡']:<6} {row['å¸‚å ´ç†±åº¦']:<8}")
        
        # å¸‚å ´ç†±åº¦åˆ†å¸ƒ
        print(f"\nğŸŒ¡ï¸ å¸‚å ´ç†±åº¦åˆ†å¸ƒ")
        heat_dist = self.city_analysis['å¸‚å ´ç†±åº¦'].value_counts()
        total_cities = len(self.city_analysis)
        for heat, count in heat_dist.items():
            percentage = (count / total_cities) * 100
            print(f"{heat}: {count} å€‹ç¸£å¸‚ ({percentage:.1f}%)")
        
        # è¡Œæ”¿å€è¡¨ç¾åˆ†æ - åªé¡¯ç¤ºæœ‰è¶³å¤ æ¨£æœ¬çš„å€åŸŸ
        print(f"\nğŸ˜ï¸ è¡Œæ”¿å€è¡¨ç¾æ’å (ç¤¾å€æ•¸â‰¥3)")
        qualified_districts = self.district_analysis[self.district_analysis['ç¤¾å€æ•¸é‡'] >= 3]
        
        print(f"{'æ’å':<4} {'ç¸£å¸‚-è¡Œæ”¿å€':<20} {'æ•´é«”å»åŒ–ç‡':<10} {'ç¤¾å€æ•¸':<6} {'ç¸½æˆ¶æ•¸':<8} {'è¡¨ç¾ç­‰ç´š':<8}")
        print("-" * 70)
        
        for idx, row in qualified_districts.head(20).iterrows():
            district_name = f"{row['ç¸£å¸‚']}-{row['è¡Œæ”¿å€']}"
            print(f"{idx+1:<4} {district_name:<20} {row['æ•´é«”å»åŒ–ç‡']:<10.1f}% "
                  f"{row['ç¤¾å€æ•¸é‡']:<6} {row['æˆ¶æ•¸']:<8,} {row['è¡¨ç¾ç­‰ç´š']:<8}")
        
        # è¡¨ç¾ç­‰ç´šåˆ†å¸ƒ
        print(f"\nğŸ“Š è¡Œæ”¿å€è¡¨ç¾ç­‰ç´šåˆ†å¸ƒ")
        grade_dist = self.district_analysis['è¡¨ç¾ç­‰ç´š'].value_counts()
        total_districts = len(self.district_analysis)
        for grade, count in grade_dist.items():
            percentage = (count / total_districts) * 100
            print(f"{grade}: {count} å€‹è¡Œæ”¿å€ ({percentage:.1f}%)")
        
        # ç‰¹åˆ¥é—œæ³¨å€åŸŸ
        print(f"\nâ­ è¡¨ç¾å„ªç•°è¡Œæ”¿å€ (å»åŒ–ç‡â‰¥80%)")
        excellent_districts = self.district_analysis[self.district_analysis['æ•´é«”å»åŒ–ç‡'] >= 80]
        if len(excellent_districts) > 0:
            for _, row in excellent_districts.iterrows():
                avg_monthly = row['æœˆå‡å»åŒ–ç‡']
                print(f"{row['ç¸£å¸‚']}-{row['è¡Œæ”¿å€']}: {row['æ•´é«”å»åŒ–ç‡']:.1f}% "
                      f"(æœˆå‡{avg_monthly:.2f}%, {row['ç¤¾å€æ•¸é‡']}å€‹ç¤¾å€)")
        else:
            print("ç›®å‰ç„¡å»åŒ–ç‡è¶…é80%çš„è¡Œæ”¿å€")
        
        print(f"\nâš ï¸ éœ€è¦é—œæ³¨è¡Œæ”¿å€ (å»åŒ–ç‡<30%ä¸”ç¤¾å€æ•¸â‰¥2)")
        concern_districts = self.district_analysis[
            (self.district_analysis['æ•´é«”å»åŒ–ç‡'] < 30) & 
            (self.district_analysis['ç¤¾å€æ•¸é‡'] >= 2)
        ].sort_values('æ•´é«”å»åŒ–ç‡')
        
        if len(concern_districts) > 0:
            for _, row in concern_districts.iterrows():
                print(f"{row['ç¸£å¸‚']}-{row['è¡Œæ”¿å€']}: {row['æ•´é«”å»åŒ–ç‡']:.1f}% "
                      f"({row['ç¤¾å€æ•¸é‡']}å€‹ç¤¾å€, {row['æˆ¶æ•¸']}æˆ¶)")
        else:
            print("ç›®å‰ç„¡éœ€ç‰¹åˆ¥é—œæ³¨çš„è¡Œæ”¿å€")
        
        # å€åŸŸç™¼å±•å»ºè­°
        print(f"\nğŸ’¡ å€åŸŸç™¼å±•å»ºè­°")
        hot_cities = self.city_analysis[self.city_analysis['å¸‚å ´ç†±åº¦'] == 'ç†±é–€']
        cold_districts = self.district_analysis[self.district_analysis['è¡¨ç¾ç­‰ç´š'] == 'å›°é›£']
        
        if len(hot_cities) > 0:
            print(f"ğŸ”¥ æ¨è–¦æŠ•è³‡ç¸£å¸‚: {', '.join(hot_cities['ç¸£å¸‚'].tolist())}")
        
        if len(cold_districts) > 0:
            print(f"âš¡ éœ€è¦ç­–ç•¥èª¿æ•´çš„è¡Œæ”¿å€: {len(cold_districts)} å€‹")
            print(f"   å»ºè­°é‡æ–°è©•ä¼°å®šåƒ¹ç­–ç•¥ã€éŠ·å”®æ–¹å¼æˆ–ç”¢å“å®šä½")
    
    def create_time_aware_visualizations(self):
        """å‰µå»ºè€ƒæ…®æ™‚é–“å› ç´ çš„è¦–è¦ºåŒ–åœ–è¡¨"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return
        
        try:
            plt.style.use('seaborn-v0_8')
        except:
            # å¦‚æœ seaborn æ¨£å¼ä¸å¯ç”¨ï¼Œä½¿ç”¨é è¨­æ¨£å¼
            pass
        
        fig, axes = plt.subplots(3, 3, figsize=(24, 18))
        fig.suptitle('é å”®å±‹å¸‚å ´æ™‚é–“èª¿æ•´åˆ†æ (å«ç¸£å¸‚è¡Œæ”¿å€)', fontsize=16, fontweight='bold')
        
        # 1. éŠ·å”®éšæ®µåˆ†å¸ƒ
        stage_dist = self.analysis_result['éŠ·å”®éšæ®µ'].value_counts()
        axes[0,0].pie(stage_dist.values, labels=stage_dist.index, autopct='%1.1f%%', startangle=90)
        axes[0,0].set_title('éŠ·å”®éšæ®µåˆ†å¸ƒ')
        
        # 2. éŠ·å”®è¡¨ç¾åˆ†å¸ƒ
        performance_dist = self.analysis_result['éŠ·å”®è¡¨ç¾'].value_counts()
        axes[0,1].bar(range(len(performance_dist)), performance_dist.values, color='lightblue')
        axes[0,1].set_xticks(range(len(performance_dist)))
        axes[0,1].set_xticklabels(performance_dist.index, rotation=45, ha='right')
        axes[0,1].set_title('éŠ·å”®è¡¨ç¾åˆ†å¸ƒ')
        axes[0,1].set_ylabel('ç¤¾å€æ•¸é‡')
        
        # 3. éŠ·å”®å¤©æ•¸ vs å»åŒ–ç‡æ•£é»åœ–
        scatter = axes[0,2].scatter(self.analysis_result['éŠ·å”®å¤©æ•¸'], self.analysis_result['å»åŒ–ç‡'], 
                                   alpha=0.6, c=self.analysis_result['æœˆå‡å»åŒ–ç‡'], cmap='viridis')
        axes[0,2].set_title('éŠ·å”®å¤©æ•¸ vs å»åŒ–ç‡')
        axes[0,2].set_xlabel('éŠ·å”®å¤©æ•¸')
        axes[0,2].set_ylabel('å»åŒ–ç‡ (%)')
        try:
            plt.colorbar(scatter, ax=axes[0,2], label='æœˆå‡å»åŒ–ç‡ (%)')
        except:
            pass
        
        # 4. ç¸£å¸‚å»åŒ–ç‡æ’å (TOP 10)
        if hasattr(self, 'city_analysis'):
            top_cities = self.city_analysis.head(10)
            bars = axes[1,0].barh(top_cities['ç¸£å¸‚'], top_cities['æ•´é«”å»åŒ–ç‡'], color='lightcoral')
            axes[1,0].set_title('ç¸£å¸‚å»åŒ–ç‡æ’å (TOP 10)')
            axes[1,0].set_xlabel('æ•´é«”å»åŒ–ç‡ (%)')
            
            # æ·»åŠ æ•¸å€¼æ¨™ç±¤
            for bar in bars:
                width = bar.get_width()
                axes[1,0].text(width + 1, bar.get_y() + bar.get_height()/2, 
                              f'{width:.1f}%', ha='left', va='center')
        
        # 5. å¸‚å ´ç†±åº¦åˆ†å¸ƒåœ“é¤…åœ–
        if hasattr(self, 'city_analysis'):
            heat_dist = self.city_analysis['å¸‚å ´ç†±åº¦'].value_counts()
            colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4']
            axes[1,1].pie(heat_dist.values, labels=heat_dist.index, autopct='%1.1f%%', 
                         colors=colors[:len(heat_dist)], startangle=90)
            axes[1,1].set_title('ç¸£å¸‚å¸‚å ´ç†±åº¦åˆ†å¸ƒ')
        
        # 6. è¡Œæ”¿å€è¡¨ç¾ç­‰ç´šåˆ†å¸ƒ
        if hasattr(self, 'district_analysis'):
            grade_dist = self.district_analysis['è¡¨ç¾ç­‰ç´š'].value_counts()
            axes[1,2].bar(grade_dist.index, grade_dist.values, color='lightgreen')
            axes[1,2].set_title('è¡Œæ”¿å€è¡¨ç¾ç­‰ç´šåˆ†å¸ƒ')
            axes[1,2].set_ylabel('è¡Œæ”¿å€æ•¸é‡')
            axes[1,2].tick_params(axis='x', rotation=45)
        
        # 7. æœˆå‡å»åŒ–ç‡åˆ†å¸ƒ
        axes[2,0].hist(self.analysis_result['æœˆå‡å»åŒ–ç‡'], bins=30, color='lightgreen', alpha=0.7)
        axes[2,0].set_title('æœˆå‡å»åŒ–ç‡åˆ†å¸ƒ')
        axes[2,0].set_xlabel('æœˆå‡å»åŒ–ç‡ (%)')
        axes[2,0].set_ylabel('ç¤¾å€æ•¸é‡')
        axes[2,0].axvline(self.analysis_result['æœˆå‡å»åŒ–ç‡'].mean(), color='red', 
                         linestyle='--', label=f'å¹³å‡: {self.analysis_result["æœˆå‡å»åŒ–ç‡"].mean():.2f}%')
        axes[2,0].legend()
        
        # 8. è¡Œæ”¿å€ç¤¾å€æ•¸ vs å¹³å‡å»åŒ–ç‡æ•£é»åœ–
        if hasattr(self, 'district_analysis'):
            scatter2 = axes[2,1].scatter(self.district_analysis['ç¤¾å€æ•¸é‡'], 
                                        self.district_analysis['æ•´é«”å»åŒ–ç‡'], 
                                        alpha=0.7, c=self.district_analysis['æˆ¶æ•¸'], 
                                        cmap='plasma', s=50)
            axes[2,1].set_title('è¡Œæ”¿å€ç¤¾å€æ•¸ vs å»åŒ–ç‡')
            axes[2,1].set_xlabel('ç¤¾å€æ•¸é‡')
            axes[2,1].set_ylabel('æ•´é«”å»åŒ–ç‡ (%)')
            try:
                plt.colorbar(scatter2, ax=axes[2,1], label='ç¸½æˆ¶æ•¸')
            except:
                pass
        
        # 9. æˆ¶æ•¸è¦æ¨¡ vs æœˆå‡å»åŒ–ç‡
        axes[2,2].scatter(self.analysis_result['æˆ¶æ•¸'], self.analysis_result['æœˆå‡å»åŒ–ç‡'], alpha=0.6)
        axes[2,2].set_title('ç¤¾å€æˆ¶æ•¸ vs æœˆå‡å»åŒ–ç‡')
        axes[2,2].set_xlabel('ç¸½æˆ¶æ•¸')
        axes[2,2].set_ylabel('æœˆå‡å»åŒ–ç‡ (%)')
        axes[2,2].set_xscale('log')
        
        plt.tight_layout()
        plt.show()
    
    def create_district_heatmap(self):
        """å‰µå»ºè¡Œæ”¿å€å»åŒ–ç‡ç†±åŠ›åœ–"""
        if not hasattr(self, 'district_analysis'):
            print("è«‹å…ˆåŸ·è¡Œè¡Œæ”¿å€åˆ†æ")
            return
        
        try:
            # å‰µå»ºæ¨ç´è¡¨ç”¨æ–¼ç†±åŠ›åœ–
            pivot_data = self.district_analysis.pivot(index='ç¸£å¸‚', columns='è¡Œæ”¿å€', values='æ•´é«”å»åŒ–ç‡')
            
            # åªé¡¯ç¤ºæœ‰è¶³å¤ æ•¸æ“šçš„ç¸£å¸‚
            pivot_data = pivot_data.dropna(how='all').fillna(0)
            
            if len(pivot_data) > 0:
                plt.figure(figsize=(16, 10))
                sns.heatmap(pivot_data, annot=True, fmt='.1f', cmap='RdYlGn', 
                           center=50, cbar_kws={'label': 'å»åŒ–ç‡ (%)'})
                plt.title('ç¸£å¸‚-è¡Œæ”¿å€å»åŒ–ç‡ç†±åŠ›åœ–', fontsize=14, fontweight='bold')
                plt.xlabel('è¡Œæ”¿å€')
                plt.ylabel('ç¸£å¸‚')
                plt.xticks(rotation=45, ha='right')
                plt.yticks(rotation=0)
                plt.tight_layout()
                plt.show()
            else:
                print("ç„¡è¶³å¤ æ•¸æ“šå‰µå»ºç†±åŠ›åœ–")
        except Exception as e:
            print(f"ç†±åŠ›åœ–å‰µå»ºå¤±æ•—: {str(e)}")
            print("å¯èƒ½æ˜¯ç”±æ–¼æ•¸æ“šçµæ§‹ä¸é©åˆæˆ–ç¼ºå°‘ seaborn å¥—ä»¶")
    
    def analyze_market_efficiency(self):
        """åˆ†æå¸‚å ´æ•ˆç‡"""
        print("\n" + "="*60)
        print("å¸‚å ´æ•ˆç‡åˆ†æ")
        print("="*60)
        
        # æ•ˆç‡æŒ‡æ¨™è¨ˆç®—
        efficient_communities = self.analysis_result[self.analysis_result['æœˆå‡å»åŒ–ç‡'] > 3]
        slow_communities = self.analysis_result[
            (self.analysis_result['éŠ·å”®å¤©æ•¸'] > 365) & 
            (self.analysis_result['å»åŒ–ç‡'] < 50)
        ]
        
        print(f"\nğŸ“ˆ å¸‚å ´æ•ˆç‡æŒ‡æ¨™")
        print(f"é«˜æ•ˆéŠ·å”®ç¤¾å€ (æœˆå‡å»åŒ–ç‡>3%): {len(efficient_communities)} å€‹")
        print(f"éŠ·å”®ç·©æ…¢ç¤¾å€ (1å¹´ä»¥ä¸Šä¸”å»åŒ–ç‡<50%): {len(slow_communities)} å€‹")
        print(f"å¸‚å ´æ•ˆç‡æ¯”: {len(efficient_communities)/(len(slow_communities)+1):.2f}")
        
        # é æ¸¬åˆ†æ
        print(f"\nğŸ”® å»åŒ–æ™‚é–“é æ¸¬")
        fast_communities = self.analysis_result[
            (self.analysis_result['æœˆå‡å»åŒ–ç‡'] > 2) & 
            (self.analysis_result['å»åŒ–ç‡'] < 80)
        ]
        
        for _, row in fast_communities.head(5).iterrows():
            remaining_rate = 100 - row['å»åŒ–ç‡']
            estimated_months = remaining_rate / row['æœˆå‡å»åŒ–ç‡'] if row['æœˆå‡å»åŒ–ç‡'] > 0 else float('inf')
            print(f"{row['ç¤¾å€åç¨±']}: é ä¼° {estimated_months:.1f} å€‹æœˆå®Œå…¨å»åŒ–")
    
    def export_time_aware_results(self, filename="time_aware_presale_analysis", format_type="csv"):
        """åŒ¯å‡ºæ™‚é–“èª¿æ•´åˆ†æçµæœ"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡Œå»åŒ–ç‡è¨ˆç®—")
            return
        
        # æº–å‚™åŒ¯å‡ºè³‡æ–™
        export_columns = ['ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¤¾å€åç¨±', 'æˆ¶æ•¸', 'å·²å”®æˆ¶æ•¸', 'å»åŒ–ç‡', 
                        'éŠ·å”®å¤©æ•¸', 'æœˆå‡å»åŒ–ç‡', 'éŠ·å”®éšæ®µ', 'éŠ·å”®è¡¨ç¾', 'é ä¼°å®Œå…¨å»åŒ–æœˆæ•¸']
        main_data = self.analysis_result[export_columns].copy()
        
        # éŠ·å”®éšæ®µåŒ¯ç¸½
        stage_summary = self.analysis_result.groupby('éŠ·å”®éšæ®µ').agg({
            'æˆ¶æ•¸': 'sum',
            'å·²å”®æˆ¶æ•¸': 'sum',
            'å»åŒ–ç‡': 'mean',
            'æœˆå‡å»åŒ–ç‡': 'mean'
        }).reset_index()
        stage_summary['æ•´é«”å»åŒ–ç‡'] = (stage_summary['å·²å”®æˆ¶æ•¸'] / stage_summary['æˆ¶æ•¸']) * 100
        
        # éŠ·å”®è¡¨ç¾åŒ¯ç¸½
        performance_summary = self.analysis_result.groupby('éŠ·å”®è¡¨ç¾').agg({
            'æˆ¶æ•¸': 'sum',
            'å·²å”®æˆ¶æ•¸': 'sum',
            'å»åŒ–ç‡': 'mean',
            'æœˆå‡å»åŒ–ç‡': 'mean'
        }).reset_index()
        performance_summary['ç¤¾å€æ•¸é‡'] = self.analysis_result.groupby('éŠ·å”®è¡¨ç¾').size().values
        
        # ç¸£å¸‚åŒ¯ç¸½ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        city_summary = None
        if hasattr(self, 'city_analysis'):
            city_summary = self.city_analysis.copy()
        
        # è¡Œæ”¿å€åŒ¯ç¸½ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        district_summary = None
        if hasattr(self, 'district_analysis'):
            district_summary = self.district_analysis.copy()
        
        if format_type.lower() == "excel":
            try:
                filename_excel = f"{filename}.xlsx"
                with pd.ExcelWriter(filename_excel, engine='openpyxl') as writer:
                    main_data.to_excel(writer, sheet_name='æ™‚é–“èª¿æ•´å»åŒ–åˆ†æ', index=False)
                    stage_summary.to_excel(writer, sheet_name='éŠ·å”®éšæ®µåŒ¯ç¸½', index=False)
                    performance_summary.to_excel(writer, sheet_name='éŠ·å”®è¡¨ç¾åŒ¯ç¸½', index=False)
                    
                    if city_summary is not None:
                        city_summary.to_excel(writer, sheet_name='ç¸£å¸‚åˆ†æ', index=False)
                    
                    if district_summary is not None:
                        district_summary.to_excel(writer, sheet_name='è¡Œæ”¿å€åˆ†æ', index=False)
                
                print(f"æ™‚é–“èª¿æ•´åˆ†æçµæœå·²åŒ¯å‡ºè‡³: {filename_excel}")
            except ImportError:
                print("âŒ ç¼ºå°‘ openpyxl å¥—ä»¶ï¼Œç„¡æ³•åŒ¯å‡º Excel æ ¼å¼")
                print("è«‹åŸ·è¡Œ: pip install openpyxl")
                print("æ”¹ç‚ºåŒ¯å‡º CSV æ ¼å¼...")
                format_type = "csv"
        
        if format_type.lower() == "csv":
            # åŒ¯å‡ºç‚ºå¤šå€‹ CSV æª”æ¡ˆ
            main_filename = f"{filename}_ä¸»è¦åˆ†æ.csv"
            stage_filename = f"{filename}_éŠ·å”®éšæ®µåŒ¯ç¸½.csv"
            performance_filename = f"{filename}_éŠ·å”®è¡¨ç¾åŒ¯ç¸½.csv"
            
            main_data.to_csv(main_filename, index=False, encoding='utf-8-sig')
            stage_summary.to_csv(stage_filename, index=False, encoding='utf-8-sig')
            performance_summary.to_csv(performance_filename, index=False, encoding='utf-8-sig')
            
            files_exported = [main_filename, stage_filename, performance_filename]
            
            if city_summary is not None:
                city_filename = f"{filename}_ç¸£å¸‚åˆ†æ.csv"
                city_summary.to_csv(city_filename, index=False, encoding='utf-8-sig')
                files_exported.append(city_filename)
            
            if district_summary is not None:
                district_filename = f"{filename}_è¡Œæ”¿å€åˆ†æ.csv"
                district_summary.to_csv(district_filename, index=False, encoding='utf-8-sig')
                files_exported.append(district_filename)
            
            print(f"æ™‚é–“èª¿æ•´åˆ†æçµæœå·²åŒ¯å‡ºç‚º CSV æ ¼å¼:")
            for file in files_exported:
                print(f"  - {file}")

# è«‹å°‡ä»¥ä¸‹æ–¹æ³•æ·»åŠ åˆ°æ‚¨çš„ PresaleMarketAnalysis é¡åˆ¥ä¸­ï¼Œä¸¦æ›¿æ› main() å‡½æ•¸

    def show_available_cities(self):
        """é¡¯ç¤ºå¯ç”¨çš„ç¸£å¸‚æ¸…å–®"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡ŒåŸºæœ¬åˆ†æ")
            return []
        
        available_cities = sorted(self.analysis_result['ç¸£å¸‚'].unique())
        print("\n" + "="*50)
        print("ğŸ“ å¯ç”¨ç¸£å¸‚æ¸…å–®")
        print("="*50)
        
        for i, city in enumerate(available_cities, 1):
            community_count = len(self.analysis_result[self.analysis_result['ç¸£å¸‚'] == city])
            units_count = self.analysis_result[self.analysis_result['ç¸£å¸‚'] == city]['æˆ¶æ•¸'].sum()
            print(f"{i:2d}. {city:<8} (ç¤¾å€: {community_count:3d}å€‹, æˆ¶æ•¸: {units_count:,}æˆ¶)")
        
        return available_cities

    def interactive_city_analysis(self):
        """äº’å‹•å¼ç¸£å¸‚åˆ†æé¸å–®"""
        if self.analysis_result is None:
            print("è«‹å…ˆåŸ·è¡ŒåŸºæœ¬åˆ†æ")
            return
        
        while True:
            print("\n" + "="*60)
            print("ğŸ¯ ç¸£å¸‚åˆ†æé¸å–®")
            print("="*60)
            print("1. ğŸ“Š æª¢è¦–æ‰€æœ‰ç¸£å¸‚æ¦‚æ³")
            print("2. ğŸ™ï¸ é¸æ“‡ç‰¹å®šç¸£å¸‚è©³ç´°åˆ†æ")
            print("3. ğŸ“‹ é¡¯ç¤ºå¯ç”¨ç¸£å¸‚æ¸…å–®")
            print("4. ğŸ” æ‰¹æ¬¡åˆ†æå¤šå€‹ç¸£å¸‚")
            print("5. ğŸ“ˆ ç¸£å¸‚æ’åæ¯”è¼ƒ")
            print("0. âŒ è¿”å›ä¸»é¸å–®")
            print("-" * 60)
            
            try:
                choice = input("è«‹é¸æ“‡åŠŸèƒ½ (0-5): ").strip()
                
                if choice == "0":
                    print("è¿”å›ä¸»é¸å–®...")
                    break
                elif choice == "1":
                    self.show_all_cities_overview()
                elif choice == "2":
                    self.select_single_city_analysis()
                elif choice == "3":
                    self.show_available_cities()
                elif choice == "4":
                    self.batch_city_analysis()
                elif choice == "5":
                    self.show_city_ranking_comparison()
                else:
                    print("âŒ ç„¡æ•ˆçš„é¸æ“‡ï¼Œè«‹è¼¸å…¥ 0-5 ä¹‹é–“çš„æ•¸å­—")
                    
            except KeyboardInterrupt:
                print("\nç¨‹å¼ä¸­æ–·ï¼Œè¿”å›ä¸»é¸å–®...")
                break
            except Exception as e:
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    def show_all_cities_overview(self):
        """é¡¯ç¤ºæ‰€æœ‰ç¸£å¸‚æ¦‚æ³"""
        if not hasattr(self, 'city_analysis'):
            print("æ­£åœ¨é€²è¡Œç¸£å¸‚åˆ†æ...")
            self.analyze_city_performance()
        
        print("\n" + "="*70)
        print("ğŸ™ï¸ å…¨ç¸£å¸‚å¸‚å ´æ¦‚æ³")
        print("="*70)
        
        print(f"{'æ’å':<4} {'ç¸£å¸‚':<8} {'å»åŒ–ç‡':<8} {'ç¤¾å€æ•¸':<6} {'æˆ¶æ•¸':<10} {'ç†±åº¦':<8}")
        print("-" * 70)
        
        for idx, row in self.city_analysis.iterrows():
            rank = idx + 1
            print(f"{rank:<4} {row['ç¸£å¸‚']:<8} {row['æ•´é«”å»åŒ–ç‡']:<8.1f}% "
                f"{row['ç¤¾å€æ•¸é‡']:<6} {row['æˆ¶æ•¸']:<10,} {row['å¸‚å ´ç†±åº¦']:<8}")

    def select_single_city_analysis(self):
        """é¸æ“‡å–®ä¸€ç¸£å¸‚é€²è¡Œè©³ç´°åˆ†æ"""
        available_cities = self.show_available_cities()
        
        if not available_cities:
            return
        
        print(f"\nè«‹é¸æ“‡è¦åˆ†æçš„ç¸£å¸‚:")
        print("è¼¸å…¥ç¸£å¸‚ç·¨è™Ÿ (1-{}) æˆ–ç›´æ¥è¼¸å…¥ç¸£å¸‚åç¨±".format(len(available_cities)))
        print("è¼¸å…¥ 'q' æˆ– '0' è¿”å›ä¸Šå±¤é¸å–®")
        
        while True:
            try:
                user_input = input("\næ‚¨çš„é¸æ“‡: ").strip()
                
                if user_input.lower() in ['q', '0', 'quit', 'exit']:
                    break
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºæ•¸å­—
                if user_input.isdigit():
                    city_index = int(user_input) - 1
                    if 0 <= city_index < len(available_cities):
                        selected_city = available_cities[city_index]
                    else:
                        print(f"âŒ è«‹è¼¸å…¥ 1-{len(available_cities)} ä¹‹é–“çš„æ•¸å­—")
                        continue
                else:
                    # ç›´æ¥è¼¸å…¥ç¸£å¸‚åç¨±
                    if user_input in available_cities:
                        selected_city = user_input
                    else:
                        # æ¨¡ç³ŠåŒ¹é…
                        matches = [city for city in available_cities if user_input in city]
                        if len(matches) == 1:
                            selected_city = matches[0]
                            print(f"æ‰¾åˆ°åŒ¹é…ç¸£å¸‚: {selected_city}")
                        elif len(matches) > 1:
                            print(f"æ‰¾åˆ°å¤šå€‹åŒ¹é…ç¸£å¸‚: {', '.join(matches)}")
                            print("è«‹è¼¸å…¥æ›´ç²¾ç¢ºçš„ç¸£å¸‚åç¨±")
                            continue
                        else:
                            print(f"âŒ æ‰¾ä¸åˆ°ç¸£å¸‚ '{user_input}'")
                            print("è«‹æª¢æŸ¥è¼¸å…¥çš„ç¸£å¸‚åç¨±æ˜¯å¦æ­£ç¢º")
                            continue
                
                # åŸ·è¡Œé¸å®šç¸£å¸‚çš„åˆ†æ
                print(f"\nğŸ¯ é–‹å§‹åˆ†æ {selected_city}...")
                self.analyze_single_city(selected_city)
                
                # è©¢å•æ˜¯å¦ç¹¼çºŒåˆ†æå…¶ä»–ç¸£å¸‚
                while True:
                    continue_choice = input(f"\næ˜¯å¦è¦åˆ†æå…¶ä»–ç¸£å¸‚? (y/n): ").strip().lower()
                    if continue_choice in ['y', 'yes', 'æ˜¯', '1']:
                        break
                    elif continue_choice in ['n', 'no', 'å¦', '0']:
                        return
                    else:
                        print("è«‹è¼¸å…¥ y æˆ– n")
                        
            except KeyboardInterrupt:
                print("\nåˆ†æä¸­æ–·")
                break
            except Exception as e:
                print(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    def batch_city_analysis(self):
        """æ‰¹æ¬¡åˆ†æå¤šå€‹ç¸£å¸‚"""
        available_cities = self.show_available_cities()
        
        if not available_cities:
            return
        
        print(f"\nğŸ“ æ‰¹æ¬¡åˆ†ææ¨¡å¼")
        print("è«‹è¼¸å…¥è¦åˆ†æçš„ç¸£å¸‚ç·¨è™Ÿï¼Œç”¨é€—è™Ÿåˆ†éš” (ä¾‹å¦‚: 1,3,5)")
        print("æˆ–è¼¸å…¥ç¸£å¸‚åç¨±ï¼Œç”¨é€—è™Ÿåˆ†éš” (ä¾‹å¦‚: å°åŒ—å¸‚,æ–°åŒ—å¸‚,æ¡ƒåœ’å¸‚)")
        print("è¼¸å…¥ 'all' åˆ†ææ‰€æœ‰ç¸£å¸‚")
        print("è¼¸å…¥ 'q' è¿”å›ä¸Šå±¤é¸å–®")
        
        try:
            user_input = input("\næ‚¨çš„é¸æ“‡: ").strip()
            
            if user_input.lower() in ['q', 'quit', 'exit']:
                return
            
            selected_cities = []
            
            if user_input.lower() == 'all':
                selected_cities = available_cities
                print(f"å°‡åˆ†ææ‰€æœ‰ {len(selected_cities)} å€‹ç¸£å¸‚")
            else:
                # è§£æç”¨æˆ¶è¼¸å…¥
                inputs = [item.strip() for item in user_input.split(',')]
                
                for inp in inputs:
                    if inp.isdigit():
                        city_index = int(inp) - 1
                        if 0 <= city_index < len(available_cities):
                            selected_cities.append(available_cities[city_index])
                        else:
                            print(f"âš ï¸ ç·¨è™Ÿ {inp} è¶…å‡ºç¯„åœï¼Œå·²è·³é")
                    else:
                        if inp in available_cities:
                            selected_cities.append(inp)
                        else:
                            print(f"âš ï¸ æ‰¾ä¸åˆ°ç¸£å¸‚ '{inp}'ï¼Œå·²è·³é")
            
            if not selected_cities:
                print("âŒ æ²’æœ‰é¸æ“‡æœ‰æ•ˆçš„ç¸£å¸‚")
                return
            
            # ç¢ºèªåˆ†æ
            print(f"\nç¢ºèªè¦åˆ†æä»¥ä¸‹ {len(selected_cities)} å€‹ç¸£å¸‚:")
            for i, city in enumerate(selected_cities, 1):
                print(f"  {i}. {city}")
            
            confirm = input(f"\nç¢ºèªé–‹å§‹æ‰¹æ¬¡åˆ†æ? (y/n): ").strip().lower()
            if confirm not in ['y', 'yes', 'æ˜¯', '1']:
                print("å·²å–æ¶ˆæ‰¹æ¬¡åˆ†æ")
                return
            
            # åŸ·è¡Œæ‰¹æ¬¡åˆ†æ
            print(f"\nğŸš€ é–‹å§‹æ‰¹æ¬¡åˆ†æ {len(selected_cities)} å€‹ç¸£å¸‚...")
            
            for i, city in enumerate(selected_cities, 1):
                print(f"\n{'='*60}")
                print(f"ğŸ“Š [{i}/{len(selected_cities)}] åˆ†æ {city}")
                print(f"{'='*60}")
                
                try:
                    self.analyze_single_city(city)
                except Exception as e:
                    print(f"âŒ {city} åˆ†æå¤±æ•—: {str(e)}")
                    continue
            
            print(f"\nâœ… æ‰¹æ¬¡åˆ†æå®Œæˆï¼å…±åˆ†æäº† {len(selected_cities)} å€‹ç¸£å¸‚")
            
        except KeyboardInterrupt:
            print("\næ‰¹æ¬¡åˆ†æä¸­æ–·")
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    def show_city_ranking_comparison(self):
        """é¡¯ç¤ºç¸£å¸‚æ’åæ¯”è¼ƒ"""
        if not hasattr(self, 'city_analysis'):
            print("æ­£åœ¨é€²è¡Œç¸£å¸‚åˆ†æ...")
            self.analyze_city_performance()
        
        print("\n" + "="*80)
        print("ğŸ† ç¸£å¸‚æ’åæ¯”è¼ƒåˆ†æ")
        print("="*80)
        
        # ä¸åŒç¶­åº¦çš„æ’å
        rankings = {
            'å»åŒ–ç‡': self.city_analysis.sort_values('æ•´é«”å»åŒ–ç‡', ascending=False),
            'ç¸½æˆ¶æ•¸': self.city_analysis.sort_values('æˆ¶æ•¸', ascending=False),
            'ç¤¾å€æ•¸': self.city_analysis.sort_values('ç¤¾å€æ•¸é‡', ascending=False),
            'æœˆå‡å»åŒ–ç‡': self.city_analysis.sort_values('æœˆå‡å»åŒ–ç‡', ascending=False)
        }
        
        print(f"\n{'æ’å':<4} ", end="")
        for metric in rankings.keys():
            print(f"{metric:<12}", end="")
        print()
        print("-" * 80)
        
        for rank in range(min(10, len(self.city_analysis))):  # é¡¯ç¤ºå‰10å
            print(f"{rank+1:<4} ", end="")
            for metric, data in rankings.items():
                city = data.iloc[rank]['ç¸£å¸‚']
                print(f"{city:<12}", end="")
            print()
        
        # å¸‚å ´ç†±åº¦åˆ†æ
        print(f"\nğŸŒ¡ï¸ å¸‚å ´ç†±åº¦åˆ†å¸ƒ:")
        heat_distribution = self.city_analysis['å¸‚å ´ç†±åº¦'].value_counts()
        for heat, count in heat_distribution.items():
            cities = self.city_analysis[self.city_analysis['å¸‚å ´ç†±åº¦'] == heat]['ç¸£å¸‚'].tolist()
            print(f"  {heat}: {count}å€‹ç¸£å¸‚ - {', '.join(cities)}")

  
        """é¡¯ç¤ºç¸£å¸‚æ’åæ¯”è¼ƒ"""
        if not hasattr(self, 'city_analysis'):
            print("æ­£åœ¨é€²è¡Œç¸£å¸‚åˆ†æ...")
            self.analyze_city_performance()
        
        print("\n" + "="*80)
        print("ğŸ† ç¸£å¸‚æ’åæ¯”è¼ƒåˆ†æ")
        print("="*80)
        
        # ä¸åŒç¶­åº¦çš„æ’å
        rankings = {
            'å»åŒ–ç‡': self.city_analysis.sort_values('æ•´é«”å»åŒ–ç‡', ascending=False),
            'ç¸½æˆ¶æ•¸': self.city_analysis.sort_values('æˆ¶æ•¸', ascending=False),
            'ç¤¾å€æ•¸': self.city_analysis.sort_values('ç¤¾å€æ•¸é‡', ascending=False),
            'æœˆå‡å»åŒ–ç‡': self.city_analysis.sort_values('æœˆå‡å»åŒ–ç‡', ascending=False)
        }
        
        print(f"\n{'æ’å':<4} ", end="")
        for metric in rankings.keys():
            print(f"{metric:<12}", end="")
        print()
        print("-" * 80)
        
        for rank in range(min(10, len(self.city_analysis))):  # é¡¯ç¤ºå‰10å
            print(f"{rank+1:<4} ", end="")
            for metric, data in rankings.items():
                city = data.iloc[rank]['ç¸£å¸‚']
                print(f"{city:<12}", end="")
            print()
        
        # å¸‚å ´ç†±åº¦åˆ†æ
        print(f"\nğŸŒ¡ï¸ å¸‚å ´ç†±åº¦åˆ†å¸ƒ:")
        heat_distribution = self.city_analysis['å¸‚å ´ç†±åº¦'].value_counts()
        for heat, count in heat_distribution.items():
            cities = self.city_analysis[self.city_analysis['å¸‚å ´ç†±åº¦'] == heat]['ç¸£å¸‚'].tolist()
            print(f"  {heat}: {count}å€‹ç¸£å¸‚ - {', '.join(cities)}")


        """é¡¯ç¤ºç¸£å¸‚æ’åæ¯”è¼ƒ"""
        if not hasattr(self, 'city_analysis'):
            print("æ­£åœ¨é€²è¡Œç¸£å¸‚åˆ†æ...")
            self.analyze_city_performance()
        
        print("\n" + "="*80)
        print("ğŸ† ç¸£å¸‚æ’åæ¯”è¼ƒåˆ†æ")
        print("="*80)
        
        # ä¸åŒç¶­åº¦çš„æ’å
        rankings = {
            'å»åŒ–ç‡': self.city_analysis.sort_values('æ•´é«”å»åŒ–ç‡', ascending=False),
            'ç¸½æˆ¶æ•¸': self.city_analysis.sort_values('æˆ¶æ•¸', ascending=False),
            'ç¤¾å€æ•¸': self.city_analysis.sort_values('ç¤¾å€æ•¸é‡', ascending=False),
            'æœˆå‡å»åŒ–ç‡': self.city_analysis.sort_values('æœˆå‡å»åŒ–ç‡', ascending=False)
        }
        
        print(f"\n{'æ’å':<4} ", end="")
        for metric in rankings.keys():
            print(f"{metric:<12}", end="")
        print()
        print("-" * 80)
        
        for rank in range(min(10, len(self.city_analysis))):  # é¡¯ç¤ºå‰10å
            print(f"{rank+1:<4} ", end="")
            for metric, data in rankings.items():
                city = data.iloc[rank]['ç¸£å¸‚']
                print(f"{city:<12}", end="")
            print()
        
        # å¸‚å ´ç†±åº¦åˆ†æ
        print(f"\nğŸŒ¡ï¸ å¸‚å ´ç†±åº¦åˆ†å¸ƒ:")
        heat_distribution = self.city_analysis['å¸‚å ´ç†±åº¦'].value_counts()
        for heat, count in heat_distribution.items():
            cities = self.city_analysis[self.city_analysis['å¸‚å ´ç†±åº¦'] == heat]['ç¸£å¸‚'].tolist()
            print(f"  {heat}: {count}å€‹ç¸£å¸‚ - {', '.join(cities)}")
        
def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    try:
        # å‰µå»ºåˆ†æå¯¦ä¾‹
        print("æ­£åœ¨åˆå§‹åŒ–åˆ†æç¨‹å¼...")
        analyzer = PresaleMarketAnalysis()

        input_dir = r"C:\pylabs\area-risk-flagging\data\lvr_moi\pre_sale_data\processed"
        fn = "é å”®å±‹è²·è³£ä¸»æª”_11006_11406.csv"
        pre_sale_input_path = os.path.join(input_dir, fn)

        input_dir = r"C:\pylabs\area-risk-flagging\data\lvr_moi\sale_data\processed"
        fn = "é å”®å±‹å‚™æŸ¥.csv"
        sale_data_input_path = os.path.join(input_dir, fn)
        
        # è¼‰å…¥ä¸¦åˆ†ææ•¸æ“š
        analyzer.load_data(pre_sale_input_path, sale_data_input_path)
        
        # é è™•ç†æ•¸æ“šï¼ˆåŒ…å«ç·¨è™Ÿæ¯”å°æª¢æŸ¥ï¼‰
        result = analyzer.preprocess_data()
        if result is None:
            print("âŒ ç”±æ–¼ç·¨è™Ÿæ¯”å°å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢åŸ·è¡Œ")
            return
        
        # åŸ·è¡ŒåŸºæœ¬åˆ†æ
        print("\n" + "="*60)
        print("åŸ·è¡ŒåŸºæœ¬å»åŒ–ç‡åˆ†æ...")
        print("="*60)
        analyzer.calculate_time_adjusted_absorption_rate()
        
        # åŸ·è¡Œç¸£å¸‚å’Œè¡Œæ”¿å€åˆ†æ
        analyzer.analyze_city_performance()
        analyzer.analyze_district_performance()
        
        # ä¸»é¸å–®è¿´åœˆ
        while True:
            print("\n" + "="*70)
            print("ğŸ  é å”®å±‹å¸‚å ´å»åŒ–ç‡åˆ†æç³»çµ±")
            print("="*70)
            print("1. ğŸ“Š æŸ¥çœ‹æ•´é«”å¸‚å ´å ±å‘Š")
            print("2. ğŸ™ï¸ ç¸£å¸‚åˆ†æé¸å–®")
            print("3. ğŸ˜ï¸ è¡Œæ”¿å€åˆ†æå ±å‘Š")
            print("4. ğŸ“ˆ å¸‚å ´æ•ˆç‡åˆ†æ")
            print("5. ğŸ“‹ ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
            print("6. ğŸ’¾ åŒ¯å‡ºåˆ†æçµæœ")
            print("7. ğŸ”„ åŸ·è¡Œå®Œæ•´åˆ†æ (æ‰€æœ‰ç¸£å¸‚)")
            print("0. ğŸšª çµæŸç¨‹å¼")
            print("-" * 70)
            
            try:
                main_choice = input("è«‹é¸æ“‡åŠŸèƒ½ (0-7): ").strip()
                
                if main_choice == "0":
                    print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨é å”®å±‹å¸‚å ´åˆ†æç³»çµ±ï¼")
                    break
                elif main_choice == "1":
                    analyzer.generate_time_aware_report()
                elif main_choice == "2":
                    analyzer.interactive_city_analysis()
                elif main_choice == "3":
                    analyzer.generate_district_city_report()
                elif main_choice == "4":
                    analyzer.analyze_market_efficiency()
                elif main_choice == "5":
                    print("\næ­£åœ¨ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
                    try:
                        analyzer.create_time_aware_visualizations()
                        analyzer.create_district_heatmap()
                    except Exception as e:
                        print(f"âš ï¸ åœ–è¡¨ç”Ÿæˆå¤±æ•—: {str(e)}")
                elif main_choice == "6":
                    export_choice = input("é¸æ“‡åŒ¯å‡ºæ ¼å¼ (csv/excel): ").strip().lower()
                    if export_choice in ['excel', 'xlsx']:
                        analyzer.export_time_aware_results("presale_analysis_results", "excel")
                    else:
                        analyzer.export_time_aware_results("presale_analysis_results", "csv")
                elif main_choice == "7":
                    print("\nğŸš€ åŸ·è¡Œå®Œæ•´åˆ†æ...")
                    # åŸ·è¡Œå®Œæ•´åˆ†æ
                    analyzer.analyze_city_detailed()
                    analyzer.generate_city_detailed_report()
                    
                    print("\næ­£åœ¨ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
                    try:
                        analyzer.create_time_aware_visualizations()
                        analyzer.create_district_heatmap()
                        
                        # ç‚ºä¸»è¦ç¸£å¸‚å‰µå»ºè©³ç´°è¦–è¦ºåŒ–
                        if hasattr(analyzer, 'city_analysis'):
                            top_cities = analyzer.city_analysis.head(3)['ç¸£å¸‚'].tolist()
                            for city in top_cities:
                                print(f"æ­£åœ¨ç”Ÿæˆ {city} è©³ç´°è¦–è¦ºåŒ–åœ–è¡¨...")
                                analyzer.create_city_visualizations(city)
                    except Exception as e:
                        print(f"âš ï¸ åœ–è¡¨ç”Ÿæˆå¤±æ•—: {str(e)}")
                    
                    # åŒ¯å‡ºçµæœ
                    analyzer.export_time_aware_results("presale_analysis_results", "csv")
                    analyzer.export_city_detailed_results("city_detailed_analysis", "csv")
                    
                    print("\nâœ… å®Œæ•´åˆ†æåŸ·è¡Œå®Œæˆï¼")
                else:
                    print("âŒ ç„¡æ•ˆçš„é¸æ“‡ï¼Œè«‹è¼¸å…¥ 0-7 ä¹‹é–“çš„æ•¸å­—")
                    
            except KeyboardInterrupt:
                print("\nç¨‹å¼ä¸­æ–·ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                print(f"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
                print("è«‹æª¢æŸ¥è³‡æ–™æ ¼å¼æˆ–è¯ç¹«é–‹ç™¼è€…")
                import traceback
                traceback.print_exc()
        
    except FileNotFoundError as e:
        print(f"âŒ æª”æ¡ˆè¼‰å…¥éŒ¯èª¤: {str(e)}")
        print("è«‹ç¢ºèª CSV æª”æ¡ˆå­˜åœ¨æ–¼æ­£ç¢ºè·¯å¾‘")
    except Exception as e:
        print(f"âŒ ç¨‹å¼åˆå§‹åŒ–éŒ¯èª¤: {str(e)}")
        print("è«‹æª¢æŸ¥è³‡æ–™æ ¼å¼æˆ–è¯ç¹«é–‹ç™¼è€…")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()




