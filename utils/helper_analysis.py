import pandas as pd
import numpy as np
import re
from typing import Dict, List, Tuple
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# ===== æ—¥æœŸè½‰æ›æ ¸å¿ƒå‡½æ•¸ =====

def parse_mixed_date_to_datetime(date_value) -> pd.Timestamp:
    """çµ±ä¸€çš„æ—¥æœŸè½‰æ›å‡½æ•¸ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼è½‰æ›ç‚ºdatetime64"""
    if pd.isna(date_value) or date_value == '' or date_value is None:
        return pd.NaT
    
    try:
        # å¦‚æœå·²ç¶“æ˜¯datetimeé¡å‹ï¼Œç›´æ¥è¿”å›
        if isinstance(date_value, (pd.Timestamp, np.datetime64)):
            return pd.Timestamp(date_value)
        
        date_str = str(date_value).strip()
        
        # è™•ç†æ°‘åœ‹å¹´æ•´æ•¸æ ¼å¼ (å¦‚: 1110701)
        if date_str.isdigit() and len(date_str) == 7:
            year = int(date_str[:3]) + 1911  # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´
            month = int(date_str[3:5])
            day = int(date_str[5:7])
            return pd.Timestamp(year, month, day)
        
        # è™•ç†æ°‘åœ‹å¹´æ–œç·šæ ¼å¼ (å¦‚: "111/07/01")
        elif '/' in date_str and len(date_str.split('/')[0]) == 3:
            parts = date_str.split('/')
            year = int(parts[0]) + 1911  # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´
            month = int(parts[1])
            day = int(parts[2])
            return pd.Timestamp(year, month, day)
        
        # è™•ç†è¥¿å…ƒå¹´æ ¼å¼ (å¦‚: "2022-07-01", "2022/07/01")
        else:
            return pd.to_datetime(date_str, errors='coerce')
            
    except Exception as e:
        return pd.NaT


def datetime_to_roc_quarter(dt_value) -> str:
    """å°‡datetime64è½‰æ›ç‚ºæ°‘åœ‹å¹´å­£æ ¼å¼ (å¦‚: 111Y2S)"""
    if pd.isna(dt_value):
        return None
    
    try:
        ts = pd.Timestamp(dt_value)
        roc_year = ts.year - 1911  # è½‰ç‚ºæ°‘åœ‹å¹´
        quarter = ts.quarter
        return f"{roc_year}Y{quarter}S"
    except:
        return None


# ===== è¼”åŠ©å‡½æ•¸ =====

def parse_id_string(text: str) -> List[str]:
    """è§£æå‚™æŸ¥ç·¨è™Ÿæ¸…å–®å­—ä¸²ï¼Œè¿”å›æ¸…ç†å¾Œçš„ç·¨è™Ÿåˆ—è¡¨"""
    if pd.isna(text) or not isinstance(text, str) or text.strip() == '':
        return []
    
    return [s.strip().strip("'\"") for s in text.split(',') if s.strip()]


# ===== åƒ¹æ ¼ç•°å¸¸å€¼éæ¿¾ =====

def filter_price_outliers_enhanced(transaction_df: pd.DataFrame, 
                                 outlier_threshold: float = 0.03) -> pd.DataFrame:
    """
    å¼·åŒ–ç‰ˆåƒ¹æ ¼ç•°å¸¸å€¼éæ¿¾ï¼Œå»é™¤æ¥µç«¯å€¼ï¼ˆä½¿ç”¨å»ºç‰©å–®åƒ¹ï¼‰
    
    Parameters:
    -----------
    transaction_df : pd.DataFrame
        äº¤æ˜“è³‡æ–™
    outlier_threshold : float
        ç•°å¸¸å€¼é–¾å€¼ï¼Œé è¨­3%ï¼ˆä¸Šä¸‹å„1.5%ï¼‰
        
    Returns:
    --------
    pd.DataFrame
        éæ¿¾å¾Œçš„äº¤æ˜“è³‡æ–™
    """
    df = transaction_df.copy()
    
    print("ğŸ“Š === åƒ¹æ ¼ç•°å¸¸å€¼éæ¿¾ï¼ˆä½¿ç”¨å»ºç‰©å–®åƒ¹ï¼‰===")
    
    # æª¢æŸ¥å»ºç‰©å–®åƒ¹æ¬„ä½æ˜¯å¦å­˜åœ¨
    if 'å»ºç‰©å–®åƒ¹' not in df.columns:
        print("  âŒ ç¼ºå°‘'å»ºç‰©å–®åƒ¹'æ¬„ä½ï¼Œç„¡æ³•é€²è¡Œåƒ¹æ ¼åˆ†æ")
        return pd.DataFrame()
    
    # éæ¿¾æ‰å»ºç‰©å–®åƒ¹ç•°å¸¸çš„è¨˜éŒ„
    valid_mask = (df['å»ºç‰©å–®åƒ¹'] > 0) & (df['å»ºç‰©å–®åƒ¹'].notna())
    df_valid = df[valid_mask]
    
    print(f"  æœ‰æ•ˆäº¤æ˜“è¨˜éŒ„ï¼š{len(df_valid)}/{len(df)} ç­†")
    
    if len(df_valid) == 0:
        print("  âš ï¸ æ²’æœ‰æœ‰æ•ˆçš„å»ºç‰©å–®åƒ¹è³‡æ–™")
        return pd.DataFrame()
    
    # è¨ˆç®—ç™¾åˆ†ä½æ•¸ï¼Œå»é™¤æ¥µç«¯å€¼
    lower_percentile = outlier_threshold / 2
    upper_percentile = 1 - (outlier_threshold / 2)
    
    price_lower = df_valid['å»ºç‰©å–®åƒ¹'].quantile(lower_percentile)
    price_upper = df_valid['å»ºç‰©å–®åƒ¹'].quantile(upper_percentile)
    
    print(f"  å»ºç‰©å–®åƒ¹ç¯„åœï¼š{price_lower:,.0f} ~ {price_upper:,.0f} è¬/åª")
    
    # éæ¿¾æ¥µç«¯å€¼
    df_filtered = df_valid[
        (df_valid['å»ºç‰©å–®åƒ¹'] >= price_lower) & 
        (df_valid['å»ºç‰©å–®åƒ¹'] <= price_upper)
    ]
    
    filtered_rate = (len(df) - len(df_filtered)) / len(df) * 100
    print(f"  éæ¿¾çµæœï¼š{len(df_filtered)}/{len(df)} ç­† (éæ¿¾ {filtered_rate:.1f}%)")
    
    return df_filtered


# ===== é‡åƒ¹æŸ¥è©¢çµæ§‹å»ºç«‹ =====

def create_quarterly_volume_price_lookup_structures(transaction_df: pd.DataFrame) -> Tuple[Dict, Dict, Dict, Dict]:
    """
    å»ºç«‹æŒ‰å­£åº¦åˆ†çµ„çš„äº¤æ˜“é‡åƒ¹æŸ¥è©¢çµæ§‹ï¼ˆä½¿ç”¨å»ºç‰©å–®åƒ¹ï¼‰
    
    Returns:
    --------
    Tuple[Dict, Dict, Dict, Dict]
        (æˆäº¤ç­†æ•¸æŸ¥è©¢è¡¨, åƒ¹æ ¼çµ±è¨ˆæŸ¥è©¢è¡¨, è¤‡åˆéµæˆäº¤ç­†æ•¸, è¤‡åˆéµåƒ¹æ ¼çµ±è¨ˆ)
    """
    print("ğŸ”§ å»ºç«‹å­£åº¦é‡åƒ¹æŸ¥è©¢çµæ§‹ï¼ˆä½¿ç”¨å»ºç‰©å–®åƒ¹ï¼‰...")
    
    # è™•ç†äº¤æ˜“è³‡æ–™
    df_processed = transaction_df.copy()
    
    # æª¢æŸ¥å»ºç‰©å–®åƒ¹æ¬„ä½
    if 'å»ºç‰©å–®åƒ¹' not in df_processed.columns:
        print("  âŒ ç¼ºå°‘'å»ºç‰©å–®åƒ¹'æ¬„ä½")
        return {}, {}, {}, {}
    
    # ç¢ºä¿äº¤æ˜“æ—¥æœŸæ˜¯datetimeæ ¼å¼
    if not pd.api.types.is_datetime64_any_dtype(df_processed['äº¤æ˜“æ—¥æœŸ']):
        df_processed['äº¤æ˜“æ—¥æœŸ'] = df_processed['äº¤æ˜“æ—¥æœŸ'].apply(parse_mixed_date_to_datetime)
    
    # è½‰æ›ç‚ºå¹´å­£
    df_processed['äº¤æ˜“å¹´å­£'] = df_processed['äº¤æ˜“æ—¥æœŸ'].apply(datetime_to_roc_quarter)
    
    # ç§»é™¤ç„¡æ•ˆå¹´å­£çš„è¨˜éŒ„
    df_processed = df_processed[df_processed['äº¤æ˜“å¹´å­£'].notna()]
    
    # å€åˆ†æ­£å¸¸äº¤æ˜“
    df_processed['æ˜¯å¦æ­£å¸¸äº¤æ˜“'] = df_processed['è§£ç´„æƒ…å½¢'].isna()
    normal_transactions = df_processed[df_processed['æ˜¯å¦æ­£å¸¸äº¤æ˜“']]
    
    print(f"  æœ‰æ•ˆæ­£å¸¸äº¤æ˜“ï¼š{len(normal_transactions)} ç­†")
    
    # åˆå§‹åŒ–çµæœå­—å…¸
    id_quarterly_counts = defaultdict(lambda: defaultdict(int))
    id_quarterly_prices = defaultdict(lambda: defaultdict(list))
    composite_quarterly_counts = defaultdict(lambda: defaultdict(int))
    composite_quarterly_prices = defaultdict(lambda: defaultdict(list))
    
    # æŒ‰å‚™æŸ¥ç·¨è™Ÿçµ±è¨ˆé‡åƒ¹
    for _, row in normal_transactions.iterrows():
        backup_id = row['å‚™æŸ¥ç·¨è™Ÿ']
        quarter = row['äº¤æ˜“å¹´å­£']
        unit_price = row['å»ºç‰©å–®åƒ¹']  # æ”¹ç”¨å»ºç‰©å–®åƒ¹
        
        if pd.notna(backup_id) and backup_id != '' and pd.notna(unit_price) and unit_price > 0:
            id_quarterly_counts[backup_id][quarter] += 1
            id_quarterly_prices[backup_id][quarter].append(unit_price)
    
    # æŒ‰è¤‡åˆéµçµ±è¨ˆé‡åƒ¹
    for _, row in normal_transactions.iterrows():
        composite_key = f"{row.get('ç¸£å¸‚', '')}|{row.get('è¡Œæ”¿å€', '')}|{row.get('ç¤¾å€åç¨±', '')}"
        quarter = row['äº¤æ˜“å¹´å­£']
        unit_price = row['å»ºç‰©å–®åƒ¹']  # æ”¹ç”¨å»ºç‰©å–®åƒ¹
        
        if pd.notna(unit_price) and unit_price > 0:
            composite_quarterly_counts[composite_key][quarter] += 1
            composite_quarterly_prices[composite_key][quarter].append(unit_price)
    
    print(f"  å»ºç«‹å®Œæˆï¼š{len(id_quarterly_counts)} å€‹å‚™æŸ¥ç·¨è™Ÿï¼Œ{len(composite_quarterly_counts)} å€‹è¤‡åˆéµ")
    
    return (dict(id_quarterly_counts), dict(id_quarterly_prices), 
            dict(composite_quarterly_counts), dict(composite_quarterly_prices))


# ===== ç¤¾å€é‡åƒ¹çµ±è¨ˆè¨ˆç®— =====

def calculate_community_quarterly_volume_price(
    row: pd.Series, 
    quarter: str,
    id_quarterly_counts: Dict,
    id_quarterly_prices: Dict,
    composite_quarterly_counts: Dict,
    composite_quarterly_prices: Dict
) -> Dict:
    """
    è¨ˆç®—å–®ä¸€ç¤¾å€åœ¨ç‰¹å®šå­£åº¦çš„é‡åƒ¹çµ±è¨ˆ
    
    Returns:
    --------
    Dict
        åŒ…å«æˆäº¤ç­†æ•¸ã€å¹³å‡å–®åƒ¹ã€ä¸­ä½æ•¸å–®åƒ¹ç­‰çµ±è¨ˆè³‡æ–™
    """
    id_list = parse_id_string(row.get('å‚™æŸ¥ç·¨è™Ÿæ¸…å–®', ''))
    
    # åˆå§‹åŒ–çµæœ
    result = {
        'è©²å­£æˆäº¤ç­†æ•¸': 0,
        'è©²å­£å¹³å‡å–®åƒ¹': 0,
        'è©²å­£ä¸­ä½æ•¸å–®åƒ¹': 0,
        'è©²å­£æœ€é«˜å–®åƒ¹': 0,
        'è©²å­£æœ€ä½å–®åƒ¹': 0,
        'è©²å­£å–®åƒ¹æ¨™æº–å·®': 0
    }
    
    all_prices = []
    total_count = 0
    
    # æ–¹æ³•1ï¼šå„ªå…ˆä½¿ç”¨å‚™æŸ¥ç·¨è™Ÿçµ±è¨ˆ
    if id_list:
        found_any = False
        
        for backup_id in id_list:
            if backup_id in id_quarterly_counts and quarter in id_quarterly_counts[backup_id]:
                count = id_quarterly_counts[backup_id][quarter]
                prices = id_quarterly_prices[backup_id][quarter]
                
                total_count += count
                all_prices.extend(prices)
                found_any = True
        
        if found_any:
            result['è©²å­£æˆäº¤ç­†æ•¸'] = total_count
            if all_prices:
                all_prices = [p for p in all_prices if pd.notna(p) and p > 0]
                if all_prices:
                    result['è©²å­£å¹³å‡å–®åƒ¹'] = np.mean(all_prices)
                    result['è©²å­£ä¸­ä½æ•¸å–®åƒ¹'] = np.median(all_prices)
                    result['è©²å­£æœ€é«˜å–®åƒ¹'] = np.max(all_prices)
                    result['è©²å­£æœ€ä½å–®åƒ¹'] = np.min(all_prices)
                    result['è©²å­£å–®åƒ¹æ¨™æº–å·®'] = np.std(all_prices) if len(all_prices) > 1 else 0
            return result
    
    # æ–¹æ³•2ï¼šä½¿ç”¨è¤‡åˆéµ
    composite_key = f"{row.get('ç¸£å¸‚', '')}|{row.get('è¡Œæ”¿å€', '')}|{row.get('ç¤¾å€åç¨±', '')}"
    
    if composite_key in composite_quarterly_counts and quarter in composite_quarterly_counts[composite_key]:
        count = composite_quarterly_counts[composite_key][quarter]
        prices = composite_quarterly_prices[composite_key][quarter]
        
        result['è©²å­£æˆäº¤ç­†æ•¸'] = count
        if prices:
            prices = [p for p in prices if pd.notna(p) and p > 0]
            if prices:
                result['è©²å­£å¹³å‡å–®åƒ¹'] = np.mean(prices)
                result['è©²å­£ä¸­ä½æ•¸å–®åƒ¹'] = np.median(prices)
                result['è©²å­£æœ€é«˜å–®åƒ¹'] = np.max(prices)
                result['è©²å­£æœ€ä½å–®åƒ¹'] = np.min(prices)
                result['è©²å­£å–®åƒ¹æ¨™æº–å·®'] = np.std(prices) if len(prices) > 1 else 0
    
    return result


# ===== ä¸»è¦è¨ˆç®—å‡½æ•¸ =====

def calculate_community_quarterly_volume_price_analysis(
    community_df: pd.DataFrame, 
    transaction_df: pd.DataFrame
) -> pd.DataFrame:
    """
    è¨ˆç®—æ¯å€‹ç¤¾å€åœ¨æ¯å€‹å­£åº¦çš„é‡åƒ¹å®Œæ•´åˆ†æ
    
    Returns:
    --------
    pd.DataFrame
        åŒ…å«æ¯å€‹ç¤¾å€æ¯å€‹å­£åº¦æˆäº¤ç­†æ•¸å’Œåƒ¹æ ¼çµ±è¨ˆçš„DataFrame
    """
    print("ğŸš€ === ç¤¾å€å­£åº¦é‡åƒ¹åˆ†æ ===")
    
    # æª¢æŸ¥å¿…è¦æ¬„ä½
    required_community_cols = ['ç·¨è™Ÿ', 'å‚™æŸ¥ç·¨è™Ÿæ¸…å–®', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¤¾å€åç¨±', 'æˆ¶æ•¸', 'éŠ·å”®èµ·å§‹æ™‚é–“']
    required_transaction_cols = ['å‚™æŸ¥ç·¨è™Ÿ', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¤¾å€åç¨±', 'äº¤æ˜“æ—¥æœŸ', 'è§£ç´„æƒ…å½¢', 'å»ºç‰©å–®åƒ¹']
    
    missing_community_cols = [col for col in required_community_cols if col not in community_df.columns]
    missing_transaction_cols = [col for col in required_transaction_cols if col not in transaction_df.columns]
    
    if missing_community_cols:
        raise ValueError(f"community_df ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_community_cols}")
    if missing_transaction_cols:
        raise ValueError(f"transaction_df ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_transaction_cols}")
    
    # 1. éæ¿¾åƒ¹æ ¼ç•°å¸¸å€¼
    # filtered_transaction_df = filter_price_outliers_enhanced(transaction_df)
    filtered_transaction_df = transaction_df
    
    if len(filtered_transaction_df) == 0:
        print("âŒ æ²’æœ‰æœ‰æ•ˆçš„äº¤æ˜“è³‡æ–™")
        return pd.DataFrame()
    
    # 2. å»ºç«‹é‡åƒ¹æŸ¥è©¢çµæ§‹
    (id_quarterly_counts, id_quarterly_prices, 
     composite_quarterly_counts, composite_quarterly_prices) = create_quarterly_volume_price_lookup_structures(filtered_transaction_df)
    
    # 3. å–å¾—æ‰€æœ‰å¯ç”¨çš„å­£åº¦
    all_quarters = set()
    valid_transactions = filtered_transaction_df[filtered_transaction_df['äº¤æ˜“æ—¥æœŸ'].notna()]
    if len(valid_transactions) > 0:
        quarters_series = valid_transactions['äº¤æ˜“æ—¥æœŸ'].apply(datetime_to_roc_quarter)
        transaction_quarters = quarters_series.dropna().unique()
        all_quarters.update(transaction_quarters)
    
    all_quarters = sorted(list(all_quarters))
    print(f"ğŸ“Š åˆ†ææ™‚é–“ç¯„åœï¼š{all_quarters[0] if all_quarters else 'None'} ~ {all_quarters[-1] if all_quarters else 'None'} ({len(all_quarters)} å€‹å­£åº¦)")
    
    # 4. è™•ç†ç¤¾å€è³‡æ–™
    community_processed = community_df.copy()
    
    # ç¢ºä¿éŠ·å”®èµ·å§‹æ™‚é–“æ˜¯datetimeæ ¼å¼
    if not pd.api.types.is_datetime64_any_dtype(community_processed['éŠ·å”®èµ·å§‹æ™‚é–“']):
        community_processed['éŠ·å”®èµ·å§‹æ™‚é–“'] = community_processed['éŠ·å”®èµ·å§‹æ™‚é–“'].apply(parse_mixed_date_to_datetime)
    
    community_processed['éŠ·å”®èµ·å§‹å¹´å­£'] = community_processed['éŠ·å”®èµ·å§‹æ™‚é–“'].apply(datetime_to_roc_quarter)
    
    # 5. è¨ˆç®—æ¯å€‹ç¤¾å€æ¯å€‹å­£åº¦çš„é‡åƒ¹çµ±è¨ˆ
    results = []
    
    print("ğŸ”„ è¨ˆç®—å„ç¤¾å€å­£åº¦é‡åƒ¹çµ±è¨ˆ...")
    processed_count = 0
    
    for _, community_row in community_processed.iterrows():
        community_id = community_row['ç·¨è™Ÿ']
        sales_start_quarter = community_row['éŠ·å”®èµ·å§‹å¹´å­£']
        
        for quarter in all_quarters:
            # åªè™•ç†éŠ·å”®èµ·å§‹å­£åº¦ä¹‹å¾Œçš„å­£åº¦
            if sales_start_quarter and quarter >= sales_start_quarter:
                # è¨ˆç®—è©²ç¤¾å€è©²å­£åº¦çš„é‡åƒ¹çµ±è¨ˆ
                volume_price_stats = calculate_community_quarterly_volume_price(
                    community_row, quarter, 
                    id_quarterly_counts, id_quarterly_prices,
                    composite_quarterly_counts, composite_quarterly_prices
                )
                
                # åªæœ‰ç•¶æœ‰äº¤æ˜“æ™‚æ‰æ·»åŠ è¨˜éŒ„
                if volume_price_stats['è©²å­£æˆäº¤ç­†æ•¸'] > 0:
                    result_row = {
                        'ç¤¾å€ç·¨è™Ÿ': community_id,
                        'ç¸£å¸‚': community_row['ç¸£å¸‚'],
                        'è¡Œæ”¿å€': community_row['è¡Œæ”¿å€'],
                        'ç¤¾å€åç¨±': community_row['ç¤¾å€åç¨±'],
                        'ç¸½æˆ¶æ•¸': community_row['æˆ¶æ•¸'],
                        'å¹´å­£': quarter,
                        'éŠ·å”®èµ·å§‹å¹´å­£': sales_start_quarter,
                        **volume_price_stats  # å±•é–‹é‡åƒ¹çµ±è¨ˆ
                    }
                    results.append(result_row)
        
        processed_count += 1
        if processed_count % 100 == 0:
            print(f"  å·²è™•ç† {processed_count}/{len(community_processed)} å€‹ç¤¾å€")
    
    result_df = pd.DataFrame(results)
    
    if len(result_df) > 0:
        # å››æ¨äº”å…¥åƒ¹æ ¼æ¬„ä½
        price_columns = ['è©²å­£å¹³å‡å–®åƒ¹', 'è©²å­£ä¸­ä½æ•¸å–®åƒ¹', 'è©²å­£æœ€é«˜å–®åƒ¹', 'è©²å­£æœ€ä½å–®åƒ¹', 'è©²å­£å–®åƒ¹æ¨™æº–å·®']
        for col in price_columns:
            result_df[col] = result_df[col].round(2)
        
        # æŒ‰ç¤¾å€å’Œå­£åº¦æ’åº
        result_df = result_df.sort_values(['ç¤¾å€ç·¨è™Ÿ', 'å¹´å­£']).reset_index(drop=True)
        
        print(f"âœ… è¨ˆç®—å®Œæˆï¼å…±ç”¢ç”Ÿ {len(result_df)} ç­†å­£åº¦é‡åƒ¹è¨˜éŒ„")
        print(f"ğŸ“ˆ æ¶µè“‹ {result_df['ç¤¾å€ç·¨è™Ÿ'].nunique()} å€‹ç¤¾å€")
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"ğŸ“Š æ•´é«”å»ºç‰©å–®åƒ¹çµ±è¨ˆï¼š")
        print(f"  å¹³å‡å»ºç‰©å–®åƒ¹ï¼š{result_df['è©²å­£å¹³å‡å–®åƒ¹'].mean():.2f} è¬/åª")
        print(f"  ä¸­ä½æ•¸å»ºç‰©å–®åƒ¹ï¼š{result_df['è©²å­£å¹³å‡å–®åƒ¹'].median():.2f} è¬/åª")
        print(f"  å»ºç‰©å–®åƒ¹ç¯„åœï¼š{result_df['è©²å­£å¹³å‡å–®åƒ¹'].min():.2f} ~ {result_df['è©²å­£å¹³å‡å–®åƒ¹'].max():.2f} è¬/åª")
        
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å­£åº¦é‡åƒ¹è¨˜éŒ„")
    
    return result_df


# ===== æ©«å‘è¡¨æ ¼è½‰æ›ï¼ˆé‡åƒ¹ç‰ˆæœ¬ï¼‰=====

def pivot_quarterly_volume_price_horizontal(quarterly_df: pd.DataFrame) -> pd.DataFrame:
    """
    å°‡å­£åº¦é‡åƒ¹è³‡æ–™è½‰æ›ç‚ºæ©«å‘æ ¼å¼ï¼ŒåŒ…å«æˆäº¤ç­†æ•¸å’Œå¹³å‡å–®åƒ¹
    
    Returns:
    --------
    pd.DataFrame
        æ©«å‘æ ¼å¼çš„é‡åƒ¹è³‡æ–™è¡¨æ ¼
    """
    if quarterly_df.empty:
        print("âš ï¸ è¼¸å…¥è³‡æ–™ç‚ºç©º")
        return pd.DataFrame()
    
    print("ğŸ”„ è½‰æ›å­£åº¦é‡åƒ¹è³‡æ–™ç‚ºæ©«å‘æ ¼å¼...")
    
    # åŸºæœ¬è³‡è¨Šæ¬„ä½
    index_cols = ['ç¤¾å€ç·¨è™Ÿ', 'ç¤¾å€åç¨±', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¸½æˆ¶æ•¸', 'éŠ·å”®èµ·å§‹å¹´å­£']
    
    # è½‰æ›æˆäº¤ç­†æ•¸
    volume_pivot = quarterly_df.pivot_table(
        index=index_cols,
        columns='å¹´å­£',
        values='è©²å­£æˆäº¤ç­†æ•¸',
        fill_value=0,
        aggfunc='sum'
    ).reset_index()
    
    # è½‰æ›å¹³å‡å»ºç‰©å–®åƒ¹
    price_pivot = quarterly_df.pivot_table(
        index=index_cols,
        columns='å¹´å­£',
        values='è©²å­£å¹³å‡å–®åƒ¹',
        fill_value=0,
        aggfunc='mean'
    ).reset_index()
    
    # åˆä½µé‡åƒ¹è³‡æ–™
    quarters = [col for col in volume_pivot.columns if col not in index_cols]
    
    # å»ºç«‹æœ€çµ‚çµæœDataFrame
    result_df = volume_pivot.copy()
    result_df.columns.name = None
    
    # ç‚ºæ¯å€‹å­£åº¦æ·»åŠ åƒ¹æ ¼æ¬„ä½
    for quarter in quarters:
        # é‡å‘½åæˆäº¤ç­†æ•¸æ¬„ä½
        volume_col = f"{quarter}_æˆäº¤ç­†æ•¸"
        price_col = f"{quarter}_å¹³å‡å»ºç‰©å–®åƒ¹"
        
        result_df = result_df.rename(columns={quarter: volume_col})
        result_df[price_col] = price_pivot[quarter].round(2)
        
        # èª¿æ•´æ¬„ä½é †åºï¼ˆæˆäº¤ç­†æ•¸åœ¨å‰ï¼Œåƒ¹æ ¼åœ¨å¾Œï¼‰
        cols = result_df.columns.tolist()
        if price_col in cols and volume_col in cols:
            # æ‰¾åˆ°volume_colçš„ä½ç½®ï¼Œå°‡price_colæ”¾åœ¨å…¶å¾Œ
            volume_idx = cols.index(volume_col)
            cols.remove(price_col)
            cols.insert(volume_idx + 1, price_col)
            result_df = result_df[cols]
    
    # æŒ‰ç¤¾å€ç·¨è™Ÿæ’åº
    result_df = result_df.sort_values('ç¤¾å€ç·¨è™Ÿ').reset_index(drop=True)
    
    quarter_count = len([col for col in result_df.columns if '_æˆäº¤ç­†æ•¸' in col])
    print(f"âœ… è½‰æ›å®Œæˆï¼å…± {len(result_df)} å€‹ç¤¾å€ï¼Œ{quarter_count} å€‹å­£åº¦ï¼ˆé‡åƒ¹é›™æŒ‡æ¨™ï¼‰")
    
    return result_df


# ===== çµ±è¨ˆåˆ†ææ“´å±•ï¼ˆé‡åƒ¹ç‰ˆæœ¬ï¼‰=====

def add_volume_price_summary_statistics(horizontal_df: pd.DataFrame) -> pd.DataFrame:
    """
    ç‚ºæ©«å‘é‡åƒ¹è¡¨æ ¼æ·»åŠ ç¶œåˆçµ±è¨ˆæ¬„ä½
    
    Returns:
    --------
    pd.DataFrame
        æ·»åŠ çµ±è¨ˆæ¬„ä½å¾Œçš„è¡¨æ ¼
    """
    df = horizontal_df.copy()
    
    print("ğŸ“Š æ·»åŠ é‡åƒ¹ç¶œåˆçµ±è¨ˆæ¬„ä½...")
    
    # è­˜åˆ¥åŸºæœ¬è³‡è¨Šæ¬„ä½å’Œå­£åº¦æ¬„ä½
    info_columns = ['ç¤¾å€ç·¨è™Ÿ', 'ç¤¾å€åç¨±', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¸½æˆ¶æ•¸', 'éŠ·å”®èµ·å§‹å¹´å­£']
    volume_columns = [col for col in df.columns if '_æˆäº¤ç­†æ•¸' in col]
    price_columns = [col for col in df.columns if '_å¹³å‡å»ºç‰©å–®åƒ¹' in col]
    
    if not volume_columns or not price_columns:
        print("âš ï¸ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„é‡åƒ¹æ¬„ä½")
        return df
    
    print(f"  æ‰¾åˆ° {len(volume_columns)} å€‹æˆäº¤é‡æ¬„ä½ï¼Œ{len(price_columns)} å€‹åƒ¹æ ¼æ¬„ä½")
    
    # === æˆäº¤é‡çµ±è¨ˆ ===
    df['ç´¯ç©æˆäº¤ç­†æ•¸'] = df[volume_columns].sum(axis=1)
    df['å¹³å‡å­£æˆäº¤ç­†æ•¸'] = df[volume_columns].mean(axis=1).round(2)
    df['æœ€å¤§å­£æˆäº¤ç­†æ•¸'] = df[volume_columns].max(axis=1)
    df['æœ‰äº¤æ˜“å­£æ•¸'] = (df[volume_columns] > 0).sum(axis=1)
    
    # === å»åŒ–ç‡åˆ†æ ===
    df['ç´¯ç©å»åŒ–ç‡(%)'] = ((df['ç´¯ç©æˆäº¤ç­†æ•¸'] / df['ç¸½æˆ¶æ•¸']) * 100).round(2)
    df['å¹³å‡å­£å»åŒ–ç‡(%)'] = ((df['å¹³å‡å­£æˆäº¤ç­†æ•¸'] / df['ç¸½æˆ¶æ•¸']) * 100).round(2)
    
    # === åƒ¹æ ¼çµ±è¨ˆ ===
    # è¨ˆç®—åŠ æ¬Šå¹³å‡å»ºç‰©å–®åƒ¹ï¼ˆä»¥æˆäº¤ç­†æ•¸ç‚ºæ¬Šé‡ï¼‰
    def calculate_weighted_avg_price(row):
        total_amount = 0
        total_volume = 0
        
        for vol_col, price_col in zip(volume_columns, price_columns):
            volume = row[vol_col]
            price = row[price_col]
            
            if volume > 0 and price > 0:
                total_amount += volume * price
                total_volume += volume
        
        return total_amount / total_volume if total_volume > 0 else 0
    
    df['åŠ æ¬Šå¹³å‡å»ºç‰©å–®åƒ¹'] = df.apply(calculate_weighted_avg_price, axis=1).round(2)
    
    # ç°¡å–®å¹³å‡å»ºç‰©å–®åƒ¹ï¼ˆå¿½ç•¥æˆäº¤é‡ï¼‰
    price_data = df[price_columns].replace(0, np.nan)
    df['ç°¡å–®å¹³å‡å»ºç‰©å–®åƒ¹'] = price_data.mean(axis=1).round(2)
    df['æœ€é«˜å»ºç‰©å–®åƒ¹'] = price_data.max(axis=1).round(2)
    df['æœ€ä½å»ºç‰©å–®åƒ¹'] = price_data.min(axis=1).round(2)
    df['å»ºç‰©å–®åƒ¹æ¨™æº–å·®'] = price_data.std(axis=1).round(2)
    
    # === åƒ¹æ ¼è¶¨å‹¢åˆ†æ ===
    if len(price_columns) >= 2:
        # é¦–å­£å’Œæœ«å­£æ¯”è¼ƒ
        first_price_col = price_columns[0]
        last_price_col = price_columns[-1]
        
        df['é¦–å­£å»ºç‰©å–®åƒ¹'] = df[first_price_col]
        df['æœ«å­£å»ºç‰©å–®åƒ¹'] = df[last_price_col]
        
        # è¨ˆç®—å»ºç‰©å–®åƒ¹è®ŠåŒ–ç‡
        def calculate_price_change_rate(row):
            first_price = row[first_price_col]
            last_price = row[last_price_col]
            
            if first_price > 0 and last_price > 0:
                return round(((last_price - first_price) / first_price * 100), 2)
            return 0
        
        df['å»ºç‰©å–®åƒ¹è®ŠåŒ–ç‡(%)'] = df.apply(calculate_price_change_rate, axis=1)
        
        # åƒ¹æ ¼è¶¨å‹¢åˆ¤æ–·
        def analyze_price_trend(change_rate):
            if change_rate > 10:
                return "ğŸ“ˆ å¤§å¹…ä¸Šæ¼²"
            elif change_rate > 3:
                return "ğŸ“ˆ æº«å’Œä¸Šæ¼²"
            elif change_rate > -3:
                return "â¡ï¸ åƒ¹æ ¼ç©©å®š"
            elif change_rate > -10:
                return "ğŸ“‰ æº«å’Œä¸‹è·Œ"
            else:
                return "ğŸ“‰ å¤§å¹…ä¸‹è·Œ"
        
        df['å»ºç‰©å–®åƒ¹è¶¨å‹¢'] = df['å»ºç‰©å–®åƒ¹è®ŠåŒ–ç‡(%)'].apply(analyze_price_trend)
    
    # === å»åŒ–æ•ˆç‡è©•ç´šï¼ˆçµåˆåƒ¹æ ¼å› ç´ ï¼‰===
    def evaluate_volume_price_efficiency(row):
        absorption_rate = row['ç´¯ç©å»åŒ–ç‡(%)']
        active_quarters = row['æœ‰äº¤æ˜“å­£æ•¸']
        avg_quarterly_rate = row['å¹³å‡å­£å»åŒ–ç‡(%)']
        price_trend = row.get('å»ºç‰©å–®åƒ¹è®ŠåŒ–ç‡(%)', 0)
        
        # åŸºç¤æ•ˆç‡è©•ç´š
        if absorption_rate >= 100:
            if active_quarters <= 8:
                base_rating = "ğŸš€ é«˜æ•ˆå®Œå”®"
            elif active_quarters <= 12:
                base_rating = "â­ æ­£å¸¸å®Œå”®"
            else:
                base_rating = "âš ï¸ ç·©æ…¢å®Œå”®"
        elif absorption_rate >= 80:
            if avg_quarterly_rate >= 3:
                base_rating = "ğŸš€ é«˜æ•ˆå»åŒ–"
            elif avg_quarterly_rate >= 1.5:
                base_rating = "â­ æ­£å¸¸å»åŒ–"
            else:
                base_rating = "âš ï¸ ç·©æ…¢å»åŒ–"
        elif absorption_rate >= 50:
            if avg_quarterly_rate >= 2:
                base_rating = "â­ æ­£å¸¸å»åŒ–"
            elif avg_quarterly_rate >= 1:
                base_rating = "âš ï¸ ç·©æ…¢å»åŒ–"
            else:
                base_rating = "ğŸŒ æ»¯éŠ·ç‹€æ…‹"
        else:
            base_rating = "ğŸ”´ åš´é‡æ»¯éŠ·"
        
        # åŠ å…¥åƒ¹æ ¼è¶¨å‹¢ä¿®æ­£
        if price_trend < -10:
            base_rating += "(åƒ¹è·Œ)"
        elif price_trend > 10:
            base_rating += "(åƒ¹æ¼²)"
            
        return base_rating
    
    df['é‡åƒ¹æ•ˆç‡è©•ç´š'] = df.apply(evaluate_volume_price_efficiency, axis=1)
    
    # === å¸‚å ´å®šä½åˆ†æ ===
    def analyze_market_position(row):
        avg_price = row['åŠ æ¬Šå¹³å‡å»ºç‰©å–®åƒ¹']
        absorption_rate = row['ç´¯ç©å»åŒ–ç‡(%)']
        
        if avg_price >= 80 and absorption_rate >= 70:
            return "ğŸ† é«˜åƒ¹ç†±éŠ·"
        elif avg_price >= 80 and absorption_rate < 50:
            return "ğŸ’ é«˜åƒ¹æ»¯éŠ·"
        elif avg_price < 40 and absorption_rate >= 70:
            return "ğŸ¯ å¹³åƒ¹ç†±éŠ·"
        elif avg_price < 40 and absorption_rate < 50:
            return "âš ï¸ å¹³åƒ¹æ»¯éŠ·"
        else:
            return "ğŸ“Š ä¸­åƒ¹ä½ç”¢å“"
    
    df['å¸‚å ´å®šä½'] = df.apply(analyze_market_position, axis=1)
    
    print("âœ… é‡åƒ¹ç¶œåˆçµ±è¨ˆæ¬„ä½æ·»åŠ å®Œæˆ")
    
    return df


# ===== å®Œæ•´å·¥ä½œæµç¨‹ =====

def complete_volume_price_analysis_workflow(
    community_file: str, 
    transaction_file: str, 
    target_city: str = None,
    output_file: str = None
) -> pd.DataFrame:
    """
    å®Œæ•´çš„é‡åƒ¹åˆ†æå·¥ä½œæµç¨‹
    
    Parameters:
    -----------
    community_file : str
        ç¤¾å€è³‡æ–™æª”æ¡ˆè·¯å¾‘
    transaction_file : str
        äº¤æ˜“è³‡æ–™æª”æ¡ˆè·¯å¾‘
    target_city : str, optional
        æŒ‡å®šåˆ†æçš„ç¸£å¸‚
    output_file : str, optional
        è¼¸å‡ºæª”æ¡ˆåç¨±
        
    Returns:
    --------
    pd.DataFrame
        å®Œæ•´çš„é‡åƒ¹åˆ†æçµæœ
    """
    print("ğŸš€ === ç¤¾å€å­£åº¦é‡åƒ¹åˆ†æå®Œæ•´å·¥ä½œæµç¨‹ ===")
    
    # 1. è¼‰å…¥è³‡æ–™
    print("\nğŸ“ Step 1: è¼‰å…¥è³‡æ–™...")
    community_df = pd.read_csv(community_file, encoding='utf-8-sig')
    transaction_df = pd.read_csv(transaction_file, encoding='utf-8-sig')
    
    print(f"ç¤¾å€è³‡æ–™ï¼š{len(community_df)} ç­†")
    print(f"äº¤æ˜“è³‡æ–™ï¼š{len(transaction_df)} ç­†")
    
    # 2. è¨ˆç®—å­£åº¦é‡åƒ¹çµ±è¨ˆ
    print(f"\nğŸ”„ Step 2: è¨ˆç®—å­£åº¦é‡åƒ¹çµ±è¨ˆ...")
    quarterly_results = calculate_community_quarterly_volume_price_analysis(community_df, transaction_df)
    
    if len(quarterly_results) == 0:
        print("âŒ æ²’æœ‰ç”¢ç”Ÿæœ‰æ•ˆçš„åˆ†æçµæœ")
        return pd.DataFrame()
    
    # 3. ç¯©é¸ç‰¹å®šç¸£å¸‚ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if target_city:
        print(f"\nğŸ“ Step 3: ç¯©é¸ç¸£å¸‚ã€{target_city}ã€‘...")
        quarterly_results = quarterly_results[quarterly_results['ç¸£å¸‚'] == target_city]
        print(f"ç¯©é¸å¾Œè¨˜éŒ„æ•¸ï¼š{len(quarterly_results)}")
    
    # 4. è½‰æ›ç‚ºæ©«å‘æ ¼å¼
    print(f"\nğŸ”„ Step 4: è½‰æ›ç‚ºæ©«å‘é‡åƒ¹æ ¼å¼...")
    horizontal_df = pivot_quarterly_volume_price_horizontal(quarterly_results)
    
    # 5. æ·»åŠ çµ±è¨ˆåˆ†æ
    print(f"\nğŸ“Š Step 5: æ·»åŠ é‡åƒ¹ç¶œåˆçµ±è¨ˆ...")
    enhanced_df = add_volume_price_summary_statistics(horizontal_df)
    
    # 6. åŒ¯å‡ºçµæœ
    if output_file is None:
        city_suffix = f"_{target_city}" if target_city else "_å…¨åœ‹"
        output_file = f'ç¤¾å€å­£åº¦é‡åƒ¹åˆ†æ{city_suffix}_{pd.Timestamp.now().strftime("%Y%m%d")}.xlsx'
    
    print(f"\nğŸ“ Step 6: åŒ¯å‡ºåˆ†æçµæœ...")
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # ä¸»è¦åˆ†æå ±å‘Š
        enhanced_df.to_excel(writer, sheet_name='é‡åƒ¹åˆ†æå ±å‘Š', index=False)
        
        # å­£åº¦æ˜ç´°è³‡æ–™
        quarterly_results.to_excel(writer, sheet_name='å­£åº¦æ˜ç´°è³‡æ–™', index=False)
        
        # æ©«å‘é‡åƒ¹è¡¨æ ¼
        horizontal_df.to_excel(writer, sheet_name='æ©«å‘é‡åƒ¹è¡¨æ ¼', index=False)
        
        # æ‘˜è¦çµ±è¨ˆ
        summary_stats = generate_summary_statistics(enhanced_df)
        summary_stats.to_excel(writer, sheet_name='æ‘˜è¦çµ±è¨ˆ', index=False)
    
    print(f"âœ… åˆ†æå®Œæˆï¼çµæœå·²åŒ¯å‡ºè‡³ï¼š{output_file}")
    print(f"ğŸ“Š æœ€çµ‚åˆ†æäº† {len(enhanced_df)} å€‹ç¤¾å€çš„é‡åƒ¹è³‡æ–™")
    
    return enhanced_df


def generate_summary_statistics(enhanced_df: pd.DataFrame) -> pd.DataFrame:
    """ç”Ÿæˆæ‘˜è¦çµ±è¨ˆè¡¨"""
    summary_data = []
    
    # æ•´é«”çµ±è¨ˆ
    summary_data.append({
        'çµ±è¨ˆé …ç›®': 'ç¤¾å€ç¸½æ•¸',
        'æ•¸å€¼': len(enhanced_df),
        'å–®ä½': 'å€‹'
    })
    
    summary_data.append({
        'çµ±è¨ˆé …ç›®': 'å¹³å‡æˆ¶æ•¸',
        'æ•¸å€¼': enhanced_df['ç¸½æˆ¶æ•¸'].mean(),
        'å–®ä½': 'æˆ¶'
    })
    
    summary_data.append({
        'çµ±è¨ˆé …ç›®': 'å¹³å‡ç´¯ç©å»åŒ–ç‡',
        'æ•¸å€¼': enhanced_df['ç´¯ç©å»åŒ–ç‡(%)'].mean(),
        'å–®ä½': '%'
    })
    
    summary_data.append({
        'çµ±è¨ˆé …ç›®': 'å¹³å‡åŠ æ¬Šå»ºç‰©å–®åƒ¹',
        'æ•¸å€¼': enhanced_df['åŠ æ¬Šå¹³å‡å»ºç‰©å–®åƒ¹'].mean(),
        'å–®ä½': 'è¬/åª'
    })
    
    # æ•ˆç‡åˆ†ç´šçµ±è¨ˆ
    efficiency_dist = enhanced_df['é‡åƒ¹æ•ˆç‡è©•ç´š'].value_counts()
    for rating, count in efficiency_dist.items():
        summary_data.append({
            'çµ±è¨ˆé …ç›®': f'æ•ˆç‡åˆ†ç´š-{rating}',
            'æ•¸å€¼': count,
            'å–®ä½': 'å€‹'
        })
    
    return pd.DataFrame(summary_data)


# ===== ä½¿ç”¨ç¯„ä¾‹ =====

def example_usage():
    """ä½¿ç”¨ç¯„ä¾‹"""
    print("ğŸ“ === é‡åƒ¹åˆ†æç³»çµ±ä½¿ç”¨ç¯„ä¾‹ ===")
    print("""
# 1. å¿«é€Ÿå®Œæ•´åˆ†æï¼ˆæ¨è–¦ï¼‰
result_df = complete_volume_price_analysis_workflow(
    'community_data_proc.csv',
    'transection_data_test.csv',
    target_city='è‡ºåŒ—å¸‚',  # å¯é¸ï¼šæŒ‡å®šç¸£å¸‚
    output_file='å°åŒ—å¸‚é‡åƒ¹åˆ†æ.xlsx'  # å¯é¸ï¼šæŒ‡å®šè¼¸å‡ºæª”æ¡ˆ
)

# 2. åˆ†æ­¥é©Ÿåˆ†æ
# è¼‰å…¥è³‡æ–™
community_df = pd.read_csv('community_data_proc.csv', encoding='utf-8-sig')
transaction_df = pd.read_csv('transection_data_test.csv', encoding='utf-8-sig')

# è¨ˆç®—å­£åº¦é‡åƒ¹çµ±è¨ˆ
quarterly_results = calculate_community_quarterly_volume_price_analysis(community_df, transaction_df)

# è½‰æ›ç‚ºæ©«å‘æ ¼å¼
horizontal_df = pivot_quarterly_volume_price_horizontal(quarterly_results)

# æ·»åŠ ç¶œåˆçµ±è¨ˆ
enhanced_df = add_volume_price_summary_statistics(horizontal_df)

# 3. æª¢è¦–çµæœé‡é»æ¬„ä½
key_columns = [
    'ç¤¾å€ç·¨è™Ÿ', 'ç¤¾å€åç¨±', 'ç¸£å¸‚', 'è¡Œæ”¿å€', 'ç¸½æˆ¶æ•¸',
    'ç´¯ç©æˆäº¤ç­†æ•¸', 'ç´¯ç©å»åŒ–ç‡(%)', 'åŠ æ¬Šå¹³å‡å»ºç‰©å–®åƒ¹',
    'å»ºç‰©å–®åƒ¹è®ŠåŒ–ç‡(%)', 'å»ºç‰©å–®åƒ¹è¶¨å‹¢', 'é‡åƒ¹æ•ˆç‡è©•ç´š', 'å¸‚å ´å®šä½'
]
print(enhanced_df[key_columns].head())

# 4. åˆ†ææ‡‰ç”¨ç¯„ä¾‹
# é«˜åƒ¹ç†±éŠ·ç¤¾å€
high_price_hot = enhanced_df[enhanced_df['å¸‚å ´å®šä½'] == 'ğŸ† é«˜åƒ¹ç†±éŠ·']
print(f"é«˜åƒ¹ç†±éŠ·ç¤¾å€ï¼š{len(high_price_hot)} å€‹")

# å»ºç‰©å–®åƒ¹ä¸Šæ¼²ä¸”å»åŒ–è‰¯å¥½çš„ç¤¾å€
price_rising_good = enhanced_df[
    (enhanced_df['å»ºç‰©å–®åƒ¹è®ŠåŒ–ç‡(%)'] > 5) & 
    (enhanced_df['ç´¯ç©å»åŒ–ç‡(%)'] > 60)
]
print(f"å»ºç‰©å–®åƒ¹ä¸Šæ¼²ä¸”å»åŒ–å¥½çš„ç¤¾å€ï¼š{len(price_rising_good)} å€‹")

# å„ç¸£å¸‚å¹³å‡å»ºç‰©å–®åƒ¹æ¯”è¼ƒ
city_price_comparison = enhanced_df.groupby('ç¸£å¸‚').agg({
    'åŠ æ¬Šå¹³å‡å»ºç‰©å–®åƒ¹': 'mean',
    'ç´¯ç©å»åŒ–ç‡(%)': 'mean',
    'ç¤¾å€ç·¨è™Ÿ': 'count'
}).round(2)
print(city_price_comparison)
    """)


if __name__ == "__main__":
    example_usage()